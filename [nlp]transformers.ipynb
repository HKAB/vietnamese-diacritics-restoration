{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[nlp]transformers",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuEKX3p4Lj7Z",
        "outputId": "8151193e-b73a-49f5-a8d8-5ebb315589de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnHMAkMA0WmC"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from typing import Tuple\n",
        "from torch.nn import functional as F\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhZ9e6-I0hz1"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2CdkCw6qRK4"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6hhbQXd0ZDo"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/NMT/final_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loHhuV2S0aiL"
      },
      "source": [
        "# tokenize by space\n",
        "tokenizer = get_tokenizer(tokenizer=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d00ytWbb0bqj"
      },
      "source": [
        "def build_vocab(iter_text_data, tokenizer):\n",
        "    counter = Counter()\n",
        "    for line in iter_text_data:#df.text_clean.to_numpy():\n",
        "        counter.update(tokenizer(line))\n",
        "    return Vocab(counter, min_freq=1000, specials=['<unk>', '<pad>', '<bos>', '<eos>'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTlPalea0bh4",
        "outputId": "47d3c373-8f23-4202-9db4-a47b7b0792c2"
      },
      "source": [
        "%%time\n",
        "tone_vocab = build_vocab(df.text_clean.to_numpy(), tokenizer)\n",
        "no_tone_vocab = build_vocab(df.text_clean_no_accent.to_numpy(), tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 16s, sys: 328 ms, total: 1min 17s\n",
            "Wall time: 1min 17s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4DLC2UkZpw8"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "PAD_IDX = tone_vocab['<pad>']\n",
        "BOS_IDX = tone_vocab['<bos>']\n",
        "EOS_IDX = tone_vocab['<eos>']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6aTKTvbOpyk",
        "outputId": "0dd115db-e2b3-4dde-97fa-f000d062212e"
      },
      "source": [
        "len(tone_vocab), len(no_tone_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4136, 2248)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IybvC0Q0dVB"
      },
      "source": [
        "def data_process(tone_array, no_tone_array, tone_vocab, no_tone_vocab, tokenizer):\n",
        "    data = []\n",
        "    for (tone_str, no_tone_str) in tqdm(zip(tone_array, no_tone_array)):\n",
        "#         print(tone_str, no_tone_str)\n",
        "#         break\n",
        "        tone_tensor_ = torch.tensor([tone_vocab[token] for token in tokenizer(tone_str)],\n",
        "                                dtype=torch.long)\n",
        "        no_tone_tensor_ = torch.tensor([no_tone_vocab[token] for token in tokenizer(no_tone_str)],\n",
        "                                dtype=torch.long)\n",
        "        data.append((tone_tensor_, no_tone_tensor_))\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBJ8nM_t0ebI",
        "outputId": "90254e82-acce-4b0f-82c9-b896fbc7f744"
      },
      "source": [
        "train_range = 100000#int(df.shape[0]*1/100)\n",
        "test_range = 1000#int(df.shape[0]*0.5/100)\n",
        "df_train = df.iloc[:train_range, :]\n",
        "df_test = df.iloc[-test_range:, :]\n",
        "df_train.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100000, 2), (1000, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCeLte6mr22g",
        "outputId": "ecd6f0de-3b36-497c-b2e9-640d0a8fa1f4"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_no_accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chây ì nộp phạt nguội</td>\n",
              "      <td>chay i nop phat nguoi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cháu đòi tiền cơm dì đòi tiền nhà</td>\n",
              "      <td>chau doi tien com di doi tien nha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>đà nẵng nghiên cứu tiện ích nhắn tin khi vi ph...</td>\n",
              "      <td>da nang nghien cuu tien ich nhan tin khi vi ph...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>khó xử vụ mẹ tuổi trộm xe hơi của con gái</td>\n",
              "      <td>kho xu vu me tuoi trom xe hoi cua con gai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thay đổi về đăng ký chuyển nhượng xe từ bạn cầ...</td>\n",
              "      <td>thay doi ve dang ky chuyen nhuong xe tu ban ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>mùi hương nổi bật năm</td>\n",
              "      <td>mui huong noi bat nam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>im lặng cho hoa nở nghi thức để đến vẻ đẹp</td>\n",
              "      <td>im lang cho hoa no nghi thuc de den ve dep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>những khoảnh khắc lịch sử của u việt nam tại c...</td>\n",
              "      <td>nhung khoanh khac lich su cua u viet nam tai c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>hành động đẹp của duy mạnh làm tan chảy trái t...</td>\n",
              "      <td>hanh dong dep cua duy manh lam tan chay trai t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>phim ngôn tình nhật bản về tình yêu thầy trò s...</td>\n",
              "      <td>phim ngon tinh nhat ban ve tinh yeu thay tro s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              text_clean                               text_clean_no_accent\n",
              "0                                  chây ì nộp phạt nguội                              chay i nop phat nguoi\n",
              "1                      cháu đòi tiền cơm dì đòi tiền nhà                  chau doi tien com di doi tien nha\n",
              "2      đà nẵng nghiên cứu tiện ích nhắn tin khi vi ph...  da nang nghien cuu tien ich nhan tin khi vi ph...\n",
              "3              khó xử vụ mẹ tuổi trộm xe hơi của con gái          kho xu vu me tuoi trom xe hoi cua con gai\n",
              "4      thay đổi về đăng ký chuyển nhượng xe từ bạn cầ...  thay doi ve dang ky chuyen nhuong xe tu ban ca...\n",
              "...                                                  ...                                                ...\n",
              "99995                              mùi hương nổi bật năm                              mui huong noi bat nam\n",
              "99996         im lặng cho hoa nở nghi thức để đến vẻ đẹp         im lang cho hoa no nghi thuc de den ve dep\n",
              "99997  những khoảnh khắc lịch sử của u việt nam tại c...  nhung khoanh khac lich su cua u viet nam tai c...\n",
              "99998  hành động đẹp của duy mạnh làm tan chảy trái t...  hanh dong dep cua duy manh lam tan chay trai t...\n",
              "99999  phim ngôn tình nhật bản về tình yêu thầy trò s...  phim ngon tinh nhat ban ve tinh yeu thay tro s...\n",
              "\n",
              "[100000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9KMqPjURl7II",
        "outputId": "281807f8-956e-4c05-8fce-5c260ea08c6b"
      },
      "source": [
        "df_test.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_no_accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9478271</th>\n",
              "      <td>quan hệ quốc phòng mỹ ấn độ thắt chặt sau thỏa...</td>\n",
              "      <td>quan he quoc phong my an do that chat sau thoa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478272</th>\n",
              "      <td>xin lãnh đạo nhịn phát biểu khai giảng</td>\n",
              "      <td>xin lanh dao nhin phat bieu khai giang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478273</th>\n",
              "      <td>bđbp tỉnh quảng nam nhận trách nhiệm trong vụ ...</td>\n",
              "      <td>bdbp tinh quang nam nhan trach nhiem trong vu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478274</th>\n",
              "      <td>premier league hù dọa châu âu bằng tỷ bảng</td>\n",
              "      <td>premier league hu doa chau au bang ty bang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478275</th>\n",
              "      <td>năm thực hiện tái cơ cấu nông nghiệp mờ nhạt b...</td>\n",
              "      <td>nam thuc hien tai co cau nong nghiep mo nhat b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text_clean                               text_clean_no_accent\n",
              "9478271  quan hệ quốc phòng mỹ ấn độ thắt chặt sau thỏa...  quan he quoc phong my an do that chat sau thoa...\n",
              "9478272             xin lãnh đạo nhịn phát biểu khai giảng             xin lanh dao nhin phat bieu khai giang\n",
              "9478273  bđbp tỉnh quảng nam nhận trách nhiệm trong vụ ...  bdbp tinh quang nam nhan trach nhiem trong vu ...\n",
              "9478274         premier league hù dọa châu âu bằng tỷ bảng         premier league hu doa chau au bang ty bang\n",
              "9478275  năm thực hiện tái cơ cấu nông nghiệp mờ nhạt b...  nam thuc hien tai co cau nong nghiep mo nhat b..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5W47MSd0fmN",
        "outputId": "fcdbcb29-05ac-4ecb-9982-d5f40ff3a805"
      },
      "source": [
        "# %%time\n",
        "train_data = data_process(df_train.text_clean.to_numpy(), \n",
        "                          df_train.text_clean_no_accent.to_numpy(), \n",
        "                          tone_vocab, no_tone_vocab, tokenizer)\n",
        "# val_data = data_process(df_test.text_clean.to_numpy(), \n",
        "#                           df_test.text_clean_no_accent.to_numpy(), \n",
        "#                           tone_vocab, no_tone_vocab, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000it [00:03, 27554.93it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40YEENGb0gvH",
        "outputId": "9562c2ad-c471-482e-a11e-3cead5406f3a"
      },
      "source": [
        "val_data = data_process(df_test.text_clean.to_numpy(), \n",
        "                          df_test.text_clean_no_accent.to_numpy(), \n",
        "                          tone_vocab, no_tone_vocab, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000it [00:00, 53404.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtRWyDdA0itJ"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "    tone_batch, no_tone_batch = [], []\n",
        "    for (tone_item, no_tone_item) in data_batch:\n",
        "        # Remove bos token\n",
        "        tone_batch.append(torch.cat([tone_item, torch.tensor([EOS_IDX])]))\n",
        "        no_tone_batch.append(torch.cat([no_tone_item, torch.tensor([EOS_IDX])]))\n",
        "        \n",
        "    tone_batch = pad_sequence(tone_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "    no_tone_batch = pad_sequence(no_tone_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "    return no_tone_batch, tone_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU4TcfdhYtrO",
        "outputId": "b9d90a4f-d5e6-4773-c83b-f5cf12332f04"
      },
      "source": [
        "PAD_IDX, BOS_IDX, EOS_IDX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtMSDuN10j6n",
        "outputId": "102872b0-888c-404e-b62c-cc57379a909f"
      },
      "source": [
        "%%time\n",
        "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 123 µs, sys: 0 ns, total: 123 µs\n",
            "Wall time: 129 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0Nq5Uie0lGA",
        "outputId": "f933abfb-71a3-488f-cb2d-ddf75f8423e0"
      },
      "source": [
        "for X, y in train_iter:\n",
        "    print(X[0])\n",
        "    print(X.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 98, 134,  33, 117, 547, 297,  14, 170,  65,  20,  22,   7,  56, 151,\n",
            "          3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1])\n",
            "torch.Size([64, 25])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve_KB6dLqV1m"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqIxRoak0vba"
      },
      "source": [
        "class DotProductAttention(nn.Module):\n",
        "  def __init__(self, dropout):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  # queries:  (batch_size*num_head x num_steps x num_hiddens/num_head) \n",
        "  # keys:     (batch_size*num_head x num_steps x num_hiddens/num_head) \n",
        "  # values:   (batch_size*num_head x num_steps x num_hiddens/num_head) \n",
        "  # mask:     (batch_size*num_heads x 1 x num_steps)\n",
        "  def forward(self, queries, keys, values, mask):\n",
        "    d = queries.shape[-1]\n",
        "    scores = torch.bmm(queries, keys.transpose(1, 2))/math.sqrt(d)\n",
        "\n",
        "    # scores: (batch_size*num_head x num_steps x num_steps)\n",
        "    # mask:   (batch_size*num_heads x 1 x num_steps)\n",
        "    # self.attention_weights: (batch_size*num_head x num_steps x num_steps)\n",
        "    self.attention_weights = F.softmax(scores.masked_fill(mask=mask, value=-np.inf), dim=-1)\n",
        "\n",
        "    # output: (batch_size*num_head x num_steps x num_hiddens/num_head)\n",
        "    return torch.bmm(self.dropout(self.attention_weights), values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v6_Bgibz_EQ",
        "outputId": "1be0bd20-d19f-4585-a6d5-89fe46243146"
      },
      "source": [
        "# How mask work\n",
        "scores = torch.ones(2, 2, 10)\n",
        "mask = (torch.rand(2, 2, 10) > 0.5)\n",
        "scores.masked_fill(mask=mask, value=-np.inf),  mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-inf, 1., -inf, -inf, -inf, 1., -inf, 1., -inf, -inf],\n",
              "          [-inf, -inf, -inf, -inf, -inf, -inf, 1., -inf, 1., -inf]],\n",
              " \n",
              "         [[-inf, 1., -inf, -inf, -inf, 1., 1., 1., -inf, -inf],\n",
              "          [-inf, -inf, 1., -inf, 1., 1., -inf, 1., 1., 1.]]]),\n",
              " tensor([[[ True, False,  True,  True,  True, False,  True, False,  True,  True],\n",
              "          [ True,  True,  True,  True,  True,  True, False,  True, False,  True]],\n",
              " \n",
              "         [[ True, False,  True,  True,  True, False, False, False,  True,  True],\n",
              "          [ True,  True, False,  True, False, False,  True, False, False, False]]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osvOvjMQL40_",
        "outputId": "31450b67-2579-42fb-977e-d6e166c29785"
      },
      "source": [
        "# with DotProductAttention, both the query and the key have the same vector length\n",
        "queries, keys = torch.normal(0, 1, (2, 1, 2)), torch.ones(2, 10, 2)\n",
        "values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)\n",
        "\n",
        "attention = DotProductAttention(0.1)\n",
        "attention.eval()\n",
        "mask = torch.stack([torch.cat((torch.zeros(2), torch.ones(8))),\n",
        "                    torch.cat((torch.zeros(6), torch.ones(4)))]).unsqueeze(1).type(torch.bool)\n",
        "attention(queries, keys, values, mask).shape, values.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 1, 4]), torch.Size([2, 10, 4]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCVqZd8WskO2"
      },
      "source": [
        "def transpose_qkv(X, num_heads):\n",
        "  # X: batch_size x key-value pairs x num_hiddens\n",
        "\n",
        "  # X shape -> batch_size x key-value pairs x num_head x num_hiddens/num_head\n",
        "  X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
        "  X = X.permute(0, 2, 1, 3)\n",
        "\n",
        "  return X.reshape(-1, X.shape[2], X.shape[3])\n",
        "def transpose_output(X, num_heads):\n",
        "  X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
        "\n",
        "  X = X.permute(0, 2, 1, 3)\n",
        "\n",
        "  return X.reshape(X.shape[0], X.shape[1], -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNsc0DA4qkto"
      },
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self, \n",
        "               key_size, query_size, value_size, \n",
        "               num_hiddens, num_heads, dropout, \n",
        "               bias=False):\n",
        "    super().__init__()\n",
        "    self.num_heads = num_heads\n",
        "    # self.attention = AdditiveAttention(int(key_size/num_heads), int(query_size/num_heads), int(num_hiddens/num_heads), dropout)\n",
        "    self.attention = DotProductAttention(dropout)\n",
        "    self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
        "    self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
        "    self.W_v = nn.Linear(value_size, num_hiddens, bias=False)\n",
        "    self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=False)\n",
        "  \n",
        "  # queries: (batch_size x num_steps x num_hiddens) \n",
        "  # keys: (batch_size x num_steps x num_hiddens) \n",
        "  # values: (batch_size x num_steps x num_hiddens) \n",
        "  # mask: (batch_size*num_heads x num_steps)\n",
        "  def forward(self, queries, keys, values, mask):\n",
        "    queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
        "    keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
        "    values = transpose_qkv(self.W_v(values), self.num_heads)\n",
        "    \n",
        "    # after transpose_qkv\n",
        "    # queries: (batch_size*num_head x num_steps x num_hiddens/num_head) \n",
        "    # keys: (batch_size*num_head x num_steps x num_hiddens/num_head) \n",
        "    # values: (batch_size*num_head x num_steps x num_hiddens/num_head) \n",
        "\n",
        "    output = self.attention(queries, keys, values, mask)\n",
        "    # output: (batch_size*num_head x num_steps x num_hiddens/num_head)\n",
        "\n",
        "    output_concat = transpose_output(output, self.num_heads)\n",
        "    # output_concat: (batch_size x num_steps x num_hiddens)\n",
        "    # print(output_concat.shape, values.shape)\n",
        "    # return shape: (batch_size x num_steps x num_hiddens)\n",
        "    return self.W_o(output_concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e893CQZQyHSl",
        "outputId": "df3b4e91-ea8d-403d-e701-dead05505fa1"
      },
      "source": [
        "num_hiddens, num_heads = 100, 5\n",
        "attention = MultiheadAttention(num_hiddens, num_hiddens, num_hiddens, \n",
        "                               num_hiddens, num_heads, 0.5)\n",
        "attention.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiheadAttention(\n",
              "  (attention): DotProductAttention(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (W_q): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (W_k): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (W_v): Linear(in_features=100, out_features=100, bias=False)\n",
              "  (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-GXz-3JysYn",
        "outputId": "270d5006-4b73-49bd-abac-f73ad87ddd09"
      },
      "source": [
        "batch_size, num_queries, num_kvpairs = 2, 10, 10\n",
        "mask = torch.stack([torch.cat((torch.zeros(2), torch.ones(8))),\n",
        "                    torch.cat((torch.zeros(6), torch.ones(4)))]).unsqueeze(1).type(torch.bool).repeat_interleave(5, dim=0)\n",
        "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
        "Y = torch.ones((batch_size, num_kvpairs, num_hiddens))\n",
        "attention(X, Y, Y, mask).shape\n",
        "# mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 10, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6GWfTyKJb0A"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, num_hiddens, dropout, max_len=1000):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.P = torch.zeros((1, max_len, num_hiddens))\n",
        "\n",
        "    X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
        "        -1, 1)/torch.pow(10000, torch.arange(0, num_hiddens, 2, dtype=torch.float32)/num_hiddens)\n",
        "    self.P[:, :, 0::2] = torch.sin(X)\n",
        "    self.P[:, :, 1::2] = torch.cos(X)\n",
        "  \n",
        "  # X: (batch_size x num_steps x num_hiddens)\n",
        "  def forward(self, X):\n",
        "    X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
        "    # return shape: (batch_size x num_steps x num_hiddens)\n",
        "    return self.dropout(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_jT-hDVSsMS"
      },
      "source": [
        "class PositionWiseFFN(nn.Module):\n",
        "  def __init__(self, ffn_num_inputs, ffn_num_hiddens, ffn_num_outputs):\n",
        "    super().__init__()\n",
        "    self.dense1 = nn.Linear(ffn_num_inputs, ffn_num_hiddens)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
        "  # X: (batch_size x num_steps x num_hiddens)\n",
        "  def forward(self, X):\n",
        "    # FFN is the same for every num_steps\n",
        "    # num_hiddens should be equal to ffn_num_inputs, ffn_num_outputs\n",
        "    # self.dense1(X): (batch_size x num_steps x ffn_num_hiddens)\n",
        "    # return shape:   (batch_size x num_steps x ffn_num_outputs)\n",
        "    return self.dense2(self.relu(self.dense1(X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItqhqQq3UMxl"
      },
      "source": [
        "class AddNorm(nn.Module):\n",
        "  def __init__(self, normalized_shape, dropout):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.ln = nn.LayerNorm(normalized_shape)\n",
        "  # X: (batch_size x num_steps x num_hiddens)\n",
        "  # Y: (batch_size x num_steps x num_hiddens)\n",
        "  def forward(self, X, Y):\n",
        "    # return shape: (batch_size x num_steps x num_hiddens)\n",
        "    return self.ln(self.dropout(Y) + X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6oF0Lm-Y41j"
      },
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
        "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
        "                 dropout, use_bias=False):\n",
        "    super().__init__()\n",
        "    self.attention = MultiheadAttention(key_size, query_size, value_size, \n",
        "                                        num_hiddens, num_heads, dropout)\n",
        "    self.addnorm1 = AddNorm(norm_shape, dropout)\n",
        "    self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
        "    self.addnorm2 = AddNorm(norm_shape, dropout)\n",
        "  # X: (batch_size x num_steps x num_hiddens) \n",
        "  # mask: (batch_size*num_heads x num_steps)\n",
        "  def forward(self, X, mask):\n",
        "    # self.attention(X, X, X, mask): (batch_size x num_steps x num_hiddens)\n",
        "    Y = self.addnorm1(X, self.attention(X, X, X, mask))\n",
        "    # Y: (batch_size x num_steps x num_hiddens)\n",
        "\n",
        "    # self.ffn(Y):  (batch_size x num_steps x num_hiddens)\n",
        "    # return shape: (batch_size x num_steps x num_hiddens)\n",
        "    return self.addnorm2(Y, self.ffn(Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmu4_fws4mk6",
        "outputId": "e3833b6f-7724-491e-9a0f-4df4ee6c8af1"
      },
      "source": [
        "X = torch.ones((2, 100, 24))\n",
        "encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
        "encoder_blk.eval()\n",
        "mask = torch.stack([torch.cat((torch.zeros(3), torch.ones(97))),\n",
        "                    torch.cat((torch.zeros(2), torch.ones(98)))]).unsqueeze(1).type(torch.bool).repeat_interleave(8, dim=0)\n",
        "encoder_blk(X, mask).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKDU96wsaoFS"
      },
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens,\n",
        "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
        "                 num_layers, dropout, use_bias=False):\n",
        "    super().__init__()\n",
        "    self.num_hiddens = num_hiddens\n",
        "    self.num_heads = num_heads\n",
        "    self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
        "    self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
        "    self.blks = nn.Sequential()\n",
        "\n",
        "    for i in range(num_layers):\n",
        "      self.blks.add_module(\n",
        "          \"block \" + str(i),\n",
        "          EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
        "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
        "                 dropout, use_bias))\n",
        "  # X: (batch_size x num_steps)\n",
        "  # mask: (batch_size*num_heads x 1 x  num_steps)\n",
        "  def forward(self, X, mask):\n",
        "    X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
        "    # X: (batch_size x num_steps x num_hiddens)\n",
        "\n",
        "    self.attention_weights = [None]*len(self.blks)\n",
        "\n",
        "    for i, blk in enumerate(self.blks):\n",
        "      # X: (batch_size x num_steps x num_hiddens)\n",
        "      X = blk(X, mask)\n",
        "      self.attention_weights[i] = blk.attention.attention.attention_weights\n",
        "\n",
        "    # return shape: (batch_size x num_steps x num_hiddens)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAxsQIiz-BF0",
        "outputId": "47497e97-6c05-4bf9-8613-77a8add8cfa3"
      },
      "source": [
        "encoder = TransformerEncoder(200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
        "encoder.eval()\n",
        "mask = torch.stack([torch.cat((torch.zeros(3), torch.ones(97))),\n",
        "                    torch.cat((torch.zeros(2), torch.ones(98)))]).unsqueeze(1).type(torch.bool).repeat_interleave(8, dim=0)\n",
        "encoder(torch.ones((2, 100), dtype=torch.long), mask).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BSK5hybeeSO"
      },
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
        "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
        "                 dropout, i):\n",
        "    super().__init__()\n",
        "    self.i = i\n",
        "    self.num_heads = num_heads\n",
        "    self.attention1 = MultiheadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
        "    # self.attention1 = DotProductAttention(dropout)\n",
        "    self.addnorm1 = AddNorm(norm_shape, dropout)\n",
        "    self.attention2 = MultiheadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
        "    self.addnorm2 = AddNorm(norm_shape, dropout)\n",
        "    self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
        "    self.addnorm3 = AddNorm(norm_shape, dropout)\n",
        "\n",
        "\n",
        "  # X:                 (batch_size x num_steps, num_hiddens)\n",
        "  # state: [(batch_size x num_steps x num_hiddens), (batch_size*num_heads x num_steps), [None]*self.num_layers]\n",
        "  def forward(self, X, state):\n",
        "    enc_outputs, enc_mask = state[0], state[1]\n",
        "    # enc_outputs: (batch_size x num_steps x num_hiddens)\n",
        "    # enc_mask:    (batch_size*num_heads x num_steps)\n",
        "\n",
        "    if state[2][self.i] is None:\n",
        "      key_values = X\n",
        "      # key_values: (batch_size x num_steps x num_hiddens)\n",
        "    else:\n",
        "      key_values = torch.cat([state[2][self.i], X], axis = 1)\n",
        "      # never run in here?\n",
        "      # print(\"layer\", self.i, \"key_values.shape\", key_values.shape)\n",
        "    state[2][self.i] = key_values\n",
        "\n",
        "    batch_size, num_steps, _ = X.shape\n",
        "    if self.training:\n",
        "      # spectial mask for each time step\n",
        "      dec_mask = torch.ones(batch_size, num_steps, num_steps).triu(diagonal=1).type(torch.bool).repeat(self.num_heads, 1, 1).to(device)\n",
        "      # dec_mask = torch.zeros(batch_size, num_steps).type(torch.bool).unsqueeze(1)#.repeat(self.num_heads, 1, 1).to(device)\n",
        "      # dec_mask: (batch_size*num_heads, 1, num_steps)\n",
        "    else:\n",
        "      dec_mask = torch.zeros(batch_size, num_steps, num_steps).type(torch.bool).repeat(self.num_heads, 1, 1).to(device)\n",
        "      # dec_mask: (batch_size*num_heads, 1, num_steps)\n",
        "    \n",
        "    # self attention?\n",
        "    X2 = self.attention1(X, key_values, key_values, dec_mask)\n",
        "    # X2: (batch_size x num_steps x num_hiddens)\n",
        "    \n",
        "    Y = self.addnorm1(X, X2)\n",
        "    # Y: (batch_size x num_steps x num_hiddens)\n",
        "\n",
        "    Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_mask)\n",
        "    # Y2: (batch_size x num_steps x num_hiddens)\n",
        "    Z = self.addnorm2(Y, Y2)\n",
        "    # Z: (batch_size x num_steps x num_hiddens)\n",
        "\n",
        "    output = self.addnorm3(Z, self.ffn(Z))\n",
        "    # output: (batch_size x num_steps x num_hiddens)\n",
        "    # state[2][self.i] is updated\n",
        "    return output, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HiFDMByMN1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1ef8a1-a48f-4c6e-b974-7dcb7129d970"
      },
      "source": [
        "# How decoder mask work\n",
        "mask = torch.ones(2, 5, 5).triu(diagonal=1).type(torch.bool).repeat(2, 1, 1).to(device)\n",
        "a = torch.rand((4, 5, 5))\n",
        "F.softmax(a.masked_fill(mask=mask, value=-np.inf), dim=-1),  mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.5613, 0.4387, 0.0000, 0.0000, 0.0000],\n",
              "          [0.3536, 0.3291, 0.3173, 0.0000, 0.0000],\n",
              "          [0.3614, 0.3127, 0.1595, 0.1663, 0.0000],\n",
              "          [0.1973, 0.1921, 0.2102, 0.2381, 0.1623]],\n",
              " \n",
              "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.5129, 0.4871, 0.0000, 0.0000, 0.0000],\n",
              "          [0.2963, 0.4471, 0.2566, 0.0000, 0.0000],\n",
              "          [0.2521, 0.2197, 0.3099, 0.2182, 0.0000],\n",
              "          [0.2073, 0.1821, 0.1760, 0.2480, 0.1866]],\n",
              " \n",
              "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.6456, 0.3544, 0.0000, 0.0000, 0.0000],\n",
              "          [0.3208, 0.3301, 0.3491, 0.0000, 0.0000],\n",
              "          [0.2718, 0.3260, 0.1964, 0.2058, 0.0000],\n",
              "          [0.1259, 0.2986, 0.1478, 0.2413, 0.1864]],\n",
              " \n",
              "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.6475, 0.3525, 0.0000, 0.0000, 0.0000],\n",
              "          [0.2071, 0.4735, 0.3194, 0.0000, 0.0000],\n",
              "          [0.2633, 0.2893, 0.2339, 0.2135, 0.0000],\n",
              "          [0.2092, 0.2526, 0.2606, 0.1442, 0.1334]]]),\n",
              " tensor([[[False,  True,  True,  True,  True],\n",
              "          [False, False,  True,  True,  True],\n",
              "          [False, False, False,  True,  True],\n",
              "          [False, False, False, False,  True],\n",
              "          [False, False, False, False, False]],\n",
              " \n",
              "         [[False,  True,  True,  True,  True],\n",
              "          [False, False,  True,  True,  True],\n",
              "          [False, False, False,  True,  True],\n",
              "          [False, False, False, False,  True],\n",
              "          [False, False, False, False, False]],\n",
              " \n",
              "         [[False,  True,  True,  True,  True],\n",
              "          [False, False,  True,  True,  True],\n",
              "          [False, False, False,  True,  True],\n",
              "          [False, False, False, False,  True],\n",
              "          [False, False, False, False, False]],\n",
              " \n",
              "         [[False,  True,  True,  True,  True],\n",
              "          [False, False,  True,  True,  True],\n",
              "          [False, False, False,  True,  True],\n",
              "          [False, False, False, False,  True],\n",
              "          [False, False, False, False, False]]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTouzd1930C6",
        "outputId": "8f9b86da-b086-4f3f-899a-cb5d55fd618e"
      },
      "source": [
        "decoder_blk = DecoderBlock(24, 24, 24, 24, [24], 24, 48, 8, 0.5, 0)\n",
        "decoder_blk.eval()\n",
        "X = torch.ones((2, 100, 24))\n",
        "mask = torch.stack([torch.cat((torch.zeros(3), torch.ones(97))),\n",
        "                    torch.cat((torch.zeros(2), torch.ones(98)))]).unsqueeze(2).type(torch.bool).repeat_interleave(8, dim=0)\n",
        "state = [encoder_blk(X, mask), mask, [None]]\n",
        "decoder_blk(X, state)[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLlVBDfQAeXe"
      },
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "  def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens,\n",
        "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers,\n",
        "                 dropout):\n",
        "    super().__init__()\n",
        "    self.num_hiddens = num_hiddens\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
        "    self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
        "    self.blks = nn.Sequential()\n",
        "    for i in range(num_layers):\n",
        "      self.blks.add_module(\n",
        "          'block' + str(i),\n",
        "          DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
        "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
        "                 dropout, i)\n",
        "      )\n",
        "      self.dense = nn.Linear(num_hiddens, vocab_size)\n",
        "  def init_state(self, enc_outputs, mask):\n",
        "    return [enc_outputs, mask, [None]*self.num_layers]\n",
        "\n",
        "  # X    : (batch_size x num_steps)\n",
        "  # state: [(batch_size x num_steps x num_hiddens), (batch_size*num_heads x num_steps), [None]*self.num_layers]\n",
        "  def forward(self, X, state):\n",
        "    \n",
        "    X = self.pos_encoding(self.embedding(X)*math.sqrt(self.num_hiddens))\n",
        "    # self.embedding(X): (batch_size x num_steps, num_hiddens)\n",
        "    # X:                 (batch_size x num_steps, num_hiddens)\n",
        "    \n",
        "    self._attention_weights = [[None] * len(self.blks) for _ in range(2)]\n",
        "\n",
        "    for i, blk in enumerate(self.blks):\n",
        "      X, state = blk(X, state)\n",
        "      # X: (batch_size x num_steps x num_hiddens)\n",
        "      # [(batch_size x num_steps x num_hiddens), (batch_size*num_heads x num_steps), [(state)]]\n",
        "      self._attention_weights[0][i] = blk.attention1.attention.attention_weights\n",
        "      self._attention_weights[1][i] = blk.attention2.attention.attention_weights\n",
        "    \n",
        "    # return shape: (batch_size x num_steps x vocab_size), [(state)]\n",
        "    return self.dense(X), state\n",
        "  def attention_weights(self):\n",
        "    return self._attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4ndnrxcDIrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f752da96-8a04-4857-d4cf-c907c83d9287"
      },
      "source": [
        "encoder = TransformerEncoder(200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
        "encoder.eval()\n",
        "mask = torch.stack([torch.cat((torch.zeros(3), torch.ones(97))),\n",
        "                    torch.cat((torch.zeros(2), torch.ones(98)))]).unsqueeze(2).type(torch.bool).repeat_interleave(8, dim=0)\n",
        "enc_outputs = encoder(torch.ones((2, 100), dtype=torch.long), mask)\n",
        "\n",
        "decoder = TransformerDecoder(200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
        "dec_state = decoder.init_state(enc_outputs, mask)\n",
        "# dec_X = torch.tensor([[2]*2]).reshape(-1, 1)\n",
        "decoder(torch.ones((2, 100), dtype=torch.long), dec_state)[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 100, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pkf84fe0oeR"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 decoder: nn.Module,\n",
        "                 pad_idx: int,\n",
        "                 device: torch.device,):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.pad_idx = pad_idx\n",
        "        self.device = device\n",
        "    def create_mask(self, src, num_heads):\n",
        "      return (src == self.pad_idx).unsqueeze(1).type(torch.bool).repeat_interleave(num_heads, dim=0).to(device)\n",
        "    # enc_X: (batch_size x num_steps)\n",
        "    # dec_X: (batch_size x num_steps)\n",
        "    def forward(self,\n",
        "                enc_X: Tensor,\n",
        "                dec_X: Tensor) -> Tensor:\n",
        "        mask = self.create_mask(enc_X, self.encoder.num_heads).to(self.device)\n",
        "        # mask: (batch_size*num_heads x 1 x num_steps)\n",
        "\n",
        "        enc_outputs = self.encoder(enc_X, mask)\n",
        "        # enc_outputs: (batch_size x num_steps x num_hiddens)\n",
        "\n",
        "        dec_state = self.decoder.init_state(enc_outputs, mask)\n",
        "        # dec_state: [enc_outputs, mask, [None]*self.num_layers]\n",
        "        # [(batch_size x num_steps x num_hiddens), (batch_size*num_heads x num_steps), [None]*self.num_layers]\n",
        "\n",
        "        # return shape: (batch_size x num_steps x vocab_size)\n",
        "        return self.decoder(dec_X, dec_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0NQ7jOm0pgT"
      },
      "source": [
        "def train_seq2seq(net, data_iter, lr, num_epochs, no_tone_vocab, device):\n",
        "    def xavier_init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "        if type(m) == nn.GRU:\n",
        "            for param in m._flat_weights_names:\n",
        "                if \"weight\" in param:\n",
        "                    nn.init.xavier_uniform_(m._parameters[param])\n",
        "    net.apply(xavier_init_weights)\n",
        "    net.to(device)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    \n",
        "    PAD_IDX = tone_vocab.stoi['<pad>']\n",
        "    loss = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "    net.train()\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for batch in tqdm(data_iter, position=0, leave=True):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            X, Y = [x.to(device) for x in batch]\n",
        "            # X: (batch_size x num_steps)\n",
        "            # Y: (batch_size x num_steps)\n",
        "            bos = torch.tensor([tone_vocab.stoi['<bos>']]*Y.shape[0], device=device).reshape(-1, 1)\n",
        "            dec_input = torch.cat([bos, Y[:, :-1]], 1) # teacher forcing\n",
        "            # dec_input: (batch_size x Y.shape[1] - 1) remove last <eos>\n",
        "            \n",
        "            Y_hat, _ = net(X, dec_input)\n",
        "            # Y_hat: (batch_size x num_steps x vocab_size)\n",
        "            # Y: (batch_size x num_steps)\n",
        "            l = loss(Y_hat.permute(0, 2, 1), Y)#nn.functional.one_hot(Y, len(no_tone_vocab)).squeeze())\n",
        "            \n",
        "            l.sum().backward()\n",
        "            \n",
        "            # clip gradient\n",
        "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "            optimizer.step()\n",
        "            epoch_loss += l.item()\n",
        "        if ((epoch + 1) % 1 == 0):\n",
        "            print(f'Epoch {epoch}, Loss {epoch_loss/len(data_iter):.10f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC4AMyRyJt4I"
      },
      "source": [
        "# def evaluate_seq2seq(net, data_iter, device):\n",
        "#   net.eval()\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#     for batch in tqdm(data_iter, position=0, leave=True):\n",
        "#       X, Y = [x.to(device) for x in batch]\n",
        "\n",
        "#       dec_X = torch.tensor([tone_vocab.stoi['<bos>']]*Y.shape[0], device=device).reshape(-1, 1)\n",
        "#       mask = (X == PAD_IDX).unsqueeze(1).type(torch.bool).repeat_interleave(net.encoder.num_heads, dim=0).to(device)\n",
        "#       enc_outputs = net.encoder(enc_X, mask)\n",
        "#       dec_state = net.decoder.init_state(enc_outputs, mask)#.repeat((1, beam_size, 1))\n",
        "\n",
        "#       for i in range(max_length):\n",
        "#         Y, dec_state = net.decoder(dec_X, dec_state)\n",
        "\n",
        "#         dec_X = Y.argmax(dim=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHQjcmYQ5so2"
      },
      "source": [
        "def evaluate(net, sentence, no_tone_vocab, tone_vocab, max_length, device, beam_size):\n",
        "  net.eval()\n",
        "\n",
        "  src_tokens = [no_tone_vocab.stoi[word] for word in sentence.lower().split(\" \")] + [no_tone_vocab.stoi['<eos>']]\n",
        "\n",
        "  # print(src_tokens)\n",
        "  # unsqueeze add more axis (add batch axis)\n",
        "  enc_X = torch.unsqueeze(\n",
        "      torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0\n",
        "  )\n",
        "\n",
        "  # create mask for encoder\n",
        "  # mask: (batch_size*num_heads x 1 x num_steps)\n",
        "  mask = (enc_X == PAD_IDX).unsqueeze(1).type(torch.bool).repeat_interleave(net.encoder.num_heads, dim=0).to(device)\n",
        "  with torch.no_grad():\n",
        "    enc_outputs = net.encoder(enc_X, mask)\n",
        "    # enc_outputs: (batch_size x num_steps x num_hiddens)\n",
        "  \n",
        "  \n",
        "  dec_state = net.decoder.init_state(enc_outputs, mask)#.repeat((1, beam_size, 1))\n",
        "  # dec_state: [enc_outputs, mask, [None]*self.num_layers]\n",
        "  # [(batch_size x num_steps x num_hiddens), (batch_size*num_heads x num_steps), [None]*self.num_layers]\n",
        "\n",
        "  dec_state[0] = dec_state[0].repeat((beam_size, 1, 1))\n",
        "  dec_state[1] = dec_state[1].repeat((beam_size, 1, 1))\n",
        "\n",
        "  beam = [Beam(beam_size, 1, 2, 3, GNMTGlobalScorer(), 5) for _ in range(1)]\n",
        "\n",
        "  for i in range(max_length):\n",
        "    if all((b.done() for b in beam)):\n",
        "      break\n",
        "    with torch.no_grad():\n",
        "      # beam search automatically return <bos> in the first time\n",
        "      dec_X = torch.stack([b.get_current_state() for b in beam]).t().contiguous().view(1, -1).t().to(device)\n",
        "      # dec_state = dec_state.squeeze(0)\n",
        "      # print(\"dec_X.shape\", dec_X.shape, \"dec_state.shape\", dec_state.shape)    \n",
        "      Y, dec_state = net.decoder(dec_X, dec_state)\n",
        "      # print(\"Y.shape after passed to decoder\", Y.shape)\n",
        "      # (beam_size, vocab_size)\n",
        "      # Y = Y.squeeze(dim=1)\n",
        "      # Y = Y.log()\n",
        "\n",
        "      select_indices_array = []\n",
        "      for j, b in enumerate(beam):\n",
        "        # print(\"Y.shape\", Y.shape)\n",
        "        # print(\"Y[:, j].shape\", Y[:, j].shape)\n",
        "        b.advance(Y[:, j])\n",
        "        \n",
        "      \n",
        "      # select_indices_array.append(b.get_current_origin() * 1 + j)\n",
        "      # print(\"select_indices_array\", select_indices_array)\n",
        "      # select_indices = torch.cat(select_indices_array) \\\n",
        "      #                 .view(1, beam_size) \\\n",
        "      #                 .transpose(0, 1) \\\n",
        "      #                 .contiguous() \\\n",
        "      #                 .view(-1).type(torch.int32).to(device)\n",
        "      # print(\"select_indices\", select_indices)\n",
        "      # dec_state = dec_state.index_select(1, select_indices)\n",
        "  ret = _from_beam(beam)\n",
        "  return ret\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QjCGct6icic"
      },
      "source": [
        "def inference(x):\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwLCaEJU0kjK"
      },
      "source": [
        "# Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSWmeEtQWSoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b469ea1-2e15-43fd-dd5b-eb988b29d252"
      },
      "source": [
        "tone_vocab_size = len(tone_vocab)\n",
        "no_tone_vocab_size = len(no_tone_vocab)\n",
        "\n",
        "num_hiddens, num_layers, dropout, batch_size, num_steps = 128, 2, 0.0, 128, 10\n",
        "lr, num_epochs = 0.001, 20\n",
        "ffn_num_input, ffn_num_hiddens, num_heads = 128, 256, 4\n",
        "key_size, query_size, value_size = 128, 128, 128\n",
        "norm_shape = [128]\n",
        "\n",
        "enc = TransformerEncoder(no_tone_vocab_size, key_size, query_size, value_size,\n",
        "                          num_hiddens, norm_shape, ffn_num_input,\n",
        "                          ffn_num_hiddens, num_heads, num_layers, dropout)\n",
        "\n",
        "dec = TransformerDecoder(tone_vocab_size, key_size, query_size, value_size,\n",
        "                          num_hiddens, norm_shape, ffn_num_input,\n",
        "                          ffn_num_hiddens, num_heads, num_layers, dropout)\n",
        "\n",
        "net = Seq2Seq(enc, dec, tone_vocab.stoi['<pad>'], device).to(device)\n",
        "\n",
        "net.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/transformers_weights.pth\", map_location=torch.device('cpu')))\n",
        "net.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (embedding): Embedding(2248, 128)\n",
              "    (pos_encoding): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (blks): Sequential(\n",
              "      (block 0): EncoderBlock(\n",
              "        (attention): MultiheadAttention(\n",
              "          (attention): DotProductAttention(\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_v): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_o): Linear(in_features=128, out_features=128, bias=False)\n",
              "        )\n",
              "        (addnorm1): AddNorm(\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (ffn): PositionWiseFFN(\n",
              "          (dense1): Linear(in_features=128, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dense2): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (addnorm2): AddNorm(\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (block 1): EncoderBlock(\n",
              "        (attention): MultiheadAttention(\n",
              "          (attention): DotProductAttention(\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_v): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_o): Linear(in_features=128, out_features=128, bias=False)\n",
              "        )\n",
              "        (addnorm1): AddNorm(\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (ffn): PositionWiseFFN(\n",
              "          (dense1): Linear(in_features=128, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dense2): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (addnorm2): AddNorm(\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): TransformerDecoder(\n",
              "    (embedding): Embedding(4136, 128)\n",
              "    (pos_encoding): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (blks): Sequential(\n",
              "      (block0): DecoderBlock(\n",
              "        (attention1): MultiheadAttention(\n",
              "          (attention): DotProductAttention(\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_v): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_o): Linear(in_features=128, out_features=128, bias=False)\n",
              "        )\n",
              "        (addnorm1): AddNorm(\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (attention2): MultiheadAttention(\n",
              "          (attention): DotProductAttention(\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_v): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_o): Linear(in_features=128, out_features=128, bias=False)\n",
              "        )\n",
              "        (addnorm2): AddNorm(\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (ffn): PositionWiseFFN(\n",
              "          (dense1): Linear(in_features=128, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dense2): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (addnorm3): AddNorm(\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (block1): DecoderBlock(\n",
              "        (attention1): MultiheadAttention(\n",
              "          (attention): DotProductAttention(\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_v): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_o): Linear(in_features=128, out_features=128, bias=False)\n",
              "        )\n",
              "        (addnorm1): AddNorm(\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (attention2): MultiheadAttention(\n",
              "          (attention): DotProductAttention(\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_v): Linear(in_features=128, out_features=128, bias=False)\n",
              "          (W_o): Linear(in_features=128, out_features=128, bias=False)\n",
              "        )\n",
              "        (addnorm2): AddNorm(\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (ffn): PositionWiseFFN(\n",
              "          (dense1): Linear(in_features=128, out_features=256, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dense2): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (addnorm3): AddNorm(\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (dense): Linear(in_features=128, out_features=4136, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqi2gA5-XRUO",
        "outputId": "d1b4bd0b-4c49-413d-e600-2e803879a915"
      },
      "source": [
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(net):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,010,152 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suq2xMLoXxmx",
        "outputId": "7e49326b-e1dd-490f-8e34-79b5743e86a2"
      },
      "source": [
        "train_seq2seq(net, train_iter, lr, num_epochs, no_tone_vocab, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:34<00:00, 44.89it/s]\n",
            "  0%|          | 5/1563 [00:00<00:35, 44.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss 4.5241308659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:34<00:00, 44.83it/s]\n",
            "  0%|          | 5/1563 [00:00<00:37, 41.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss 1.8142873072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:34<00:00, 44.69it/s]\n",
            "  0%|          | 5/1563 [00:00<00:37, 41.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss 1.2322631132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.62it/s]\n",
            "  0%|          | 5/1563 [00:00<00:34, 45.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss 0.9823733826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.48it/s]\n",
            "  0%|          | 5/1563 [00:00<00:36, 43.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss 0.8440905663\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:34<00:00, 44.69it/s]\n",
            "  0%|          | 5/1563 [00:00<00:37, 41.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss 0.7178445387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.50it/s]\n",
            "  0%|          | 5/1563 [00:00<00:34, 44.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss 0.6424244722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.54it/s]\n",
            "  0%|          | 5/1563 [00:00<00:37, 41.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss 0.5635342047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.46it/s]\n",
            "  0%|          | 5/1563 [00:00<00:34, 44.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss 0.5156823907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.44it/s]\n",
            "  0%|          | 5/1563 [00:00<00:36, 43.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss 0.4828316741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.46it/s]\n",
            "  0%|          | 5/1563 [00:00<00:35, 43.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss 0.4337879226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.52it/s]\n",
            "  0%|          | 5/1563 [00:00<00:35, 43.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11, Loss 0.3993516293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.32it/s]\n",
            "  0%|          | 5/1563 [00:00<00:37, 41.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12, Loss 0.3681752286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.10it/s]\n",
            "  0%|          | 5/1563 [00:00<00:34, 45.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13, Loss 0.3379901801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.41it/s]\n",
            "  0%|          | 5/1563 [00:00<00:35, 43.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14, Loss 0.3168007072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.38it/s]\n",
            "  0%|          | 5/1563 [00:00<00:37, 41.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15, Loss 0.2954433392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.47it/s]\n",
            "  0%|          | 5/1563 [00:00<00:35, 44.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16, Loss 0.2883934329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.33it/s]\n",
            "  0%|          | 5/1563 [00:00<00:36, 42.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17, Loss 0.2727549379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.36it/s]\n",
            "  0%|          | 5/1563 [00:00<00:34, 44.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18, Loss 0.2587469967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:35<00:00, 44.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19, Loss 0.2473383568\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AQ0yY4g1oE-"
      },
      "source": [
        "# torch.save(net.state_dict(), '/content/drive/MyDrive/Colab Notebooks/transformers_weights.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAvL1e2O0r4Z"
      },
      "source": [
        "# Beam search & Attention visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ItIvkj3ARfO"
      },
      "source": [
        "class GNMTGlobalScorer(object):\n",
        "    \"\"\"\n",
        "    NMT re-ranking score from\n",
        "    \"Google's Neural Machine Translation System\" :cite:`wu2016google`\n",
        "    Args:\n",
        "       alpha (float): length parameter\n",
        "       beta (float):  coverage parameter\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "    def score(self, beam, logprobs):\n",
        "        # \"\"\"\n",
        "        # Rescores a prediction based on penalty functions\n",
        "        # \"\"\"\n",
        "        # normalized_probs = self.length_penalty(beam,\n",
        "        #                                        logprobs,\n",
        "        #                                        self.alpha)\n",
        "        # if not beam.stepwise_penalty:\n",
        "        #     penalty = self.cov_penalty(beam,\n",
        "        #                                beam.global_state[\"coverage\"],\n",
        "        #                                self.beta)\n",
        "        #     normalized_probs -= penalty\n",
        "\n",
        "        return logprobs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XgD5iauWros"
      },
      "source": [
        "class Beam(object):\n",
        "  def __init__(self, size, pad, bos, eos, global_scorer, min_length):\n",
        "    super().__init__()\n",
        "    self.prev_ks = []\n",
        "    self.scores = torch.FloatTensor(size).zero_()\n",
        "    self.all_scores = []\n",
        "\n",
        "    self.min_length = min_length\n",
        "\n",
        "    self.next_ys = [torch.LongTensor(size)\n",
        "                        .fill_(pad)]\n",
        "    self.next_ys[0][0] = bos\n",
        "\n",
        "    self.finished = []\n",
        "\n",
        "    self.global_scorer = global_scorer\n",
        "\n",
        "    self._eos = eos\n",
        "    self.eos_top = False\n",
        "\n",
        "    self.size = size\n",
        "\n",
        "  def get_current_state(self):\n",
        "    \"Get the outputs for the current timestep.\"\n",
        "    return self.next_ys[-1]\n",
        "\n",
        "  def get_current_origin(self):\n",
        "    \"Get the backpointers for the current timestep.\"\n",
        "    return self.prev_ks[-1]\n",
        "  def done(self):\n",
        "    return self.eos_top\n",
        "  def sort_finished(self, minimum=None):\n",
        "    if minimum is not None:\n",
        "        i = 0\n",
        "        # Add from beam until we have minimum outputs.\n",
        "        while len(self.finished) < minimum:\n",
        "            global_scores = self.global_scorer.score(self, self.scores)\n",
        "            s = global_scores[i]\n",
        "            self.finished.append((s, len(self.next_ys) - 1, i))\n",
        "            i += 1\n",
        "\n",
        "    self.finished.sort(key=lambda a: -a[0])\n",
        "    scores = [sc for sc, _, _ in self.finished]\n",
        "    ks = [(t, k) for _, t, k in self.finished]\n",
        "    return scores, ks\n",
        "\n",
        "  def get_hyp(self, timestep, k):\n",
        "      \"\"\"\n",
        "      Walk back to construct the full hypothesis.\n",
        "      \"\"\"\n",
        "      hyp = []\n",
        "      for j in range(len(self.prev_ks[:timestep]) - 1, -1, -1):\n",
        "          hyp.append(self.next_ys[j + 1][k])\n",
        "          k = self.prev_ks[j][k]\n",
        "      return hyp[::-1]\n",
        "  def advance(self, word_probs):\n",
        "    word_probs = word_probs.unsqueeze(0)\n",
        "    # print(\"word_probs\", word_probs.shape)\n",
        "    num_words = word_probs.size(2)\n",
        "    \n",
        "    # dont let this shit end\n",
        "    cur_len = len(self.next_ys)\n",
        "    # print(\"cur_len\", cur_len)\n",
        "    if cur_len < self.min_length:\n",
        "        for k in range(len(word_probs)):\n",
        "            word_probs[0][k][self._eos] = -1e20\n",
        "            # print(\"word\", self._eos, \"has\", word_probs[k][self._eos])\n",
        "\n",
        "    if len(self.prev_ks) > 0:\n",
        "      beam_scores = word_probs + self.scores.unsqueeze(1).expand_as(word_probs).to(device)\n",
        "      # print(\"beam_scores.shape\", beam_scores.shape, \"word_probs\", word_probs.shape, \"self.scores.unsqueeze(1).expand_as(word_probs)\", self.scores.unsqueeze(1).expand_as(word_probs).shape)\n",
        "      beam_scores = beam_scores.squeeze(0)\n",
        "      # print(\"beam_scores\", beam_scores)\n",
        "      for i in range(self.next_ys[-1].size(0)):\n",
        "        if self.next_ys[-1][i] == self._eos:\n",
        "          # print(\"sentence\", i, 'is ended')\n",
        "          beam_scores[i] = -1e20\n",
        "    else:\n",
        "      beam_scores = word_probs[0][0]\n",
        "      # print(\"beam_scores.shape first time\", beam_scores.shape)\n",
        "\n",
        "    \n",
        "    flat_beam_scores = beam_scores.view(-1)\n",
        "    # print(\"self.size\", self.size, \"flat_beam_scores.shape\", flat_beam_scores.shape)\n",
        "    \n",
        "    best_scores, best_scores_id = flat_beam_scores.topk(self.size, 0,\n",
        "        True, True)\n",
        "    \n",
        "    self.all_scores.append(self.scores)\n",
        "    self.scores = best_scores\n",
        "    # print(\"best_scores\", best_scores, \"best_scores_id\", best_scores_id)\n",
        "    \n",
        "    # print(\"flat_beam_scores\", flat_beam_scores, \"best_scores\", best_scores, \"best_scores_id\", best_scores_id)\n",
        "    # print(\"num_words\", num_words)\n",
        "    prev_k = torch.floor(best_scores_id / num_words).long()\n",
        "    # print(\"prev_k\", prev_k)\n",
        "    self.prev_ks.append(prev_k)\n",
        "    self.next_ys.append((best_scores_id - prev_k * num_words))\n",
        "    # print(\"self.prev_ks\", self.prev_ks)\n",
        "    # print(\"self.next_ys\", self.next_ys)\n",
        "    for i in range(self.next_ys[-1].size(0)):\n",
        "      if self.next_ys[-1][i] == self._eos:\n",
        "        # print(\"self.scores\", self.scores)\n",
        "        global_scores = self.global_scorer.score(self, self.scores)\n",
        "        s = global_scores[i]\n",
        "        self.finished.append((s, len(self.next_ys) - 1, i))\n",
        "\n",
        "    if self.next_ys[-1][0] == self._eos:\n",
        "      self.all_scores.append(self.scores)\n",
        "      self.eos_top = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nbJUZ9KVJ7d"
      },
      "source": [
        "def _from_beam(beam):\n",
        "    ret = {\"predictions\": [],\n",
        "            \"scores\": [],\n",
        "            \"attention\": []}\n",
        "    for b in beam:\n",
        "        # n_best = self.n_best\n",
        "        scores, ks = b.sort_finished(minimum=None)\n",
        "        # print(scores, ks)\n",
        "        hyps, attn = [], []\n",
        "        for i, (times, k) in enumerate(ks):#[:n_best]):\n",
        "            # hyp, att = b.get_hyp(times, k)\n",
        "            hyp = b.get_hyp(times, k)\n",
        "            hyps.append(hyp)\n",
        "            # attn.append(att)\n",
        "        ret[\"predictions\"].append(hyps)\n",
        "        ret[\"scores\"].append(scores)\n",
        "        # ret[\"attention\"].append(attn)\n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekw6sJ2EJSVT",
        "outputId": "450520f1-8acd-4a47-ec05-61bcb7e8424c"
      },
      "source": [
        "sentence = \"Tram nam trong coi nguoi ta\"\n",
        "beam = evaluate(net, sentence, no_tone_vocab, tone_vocab, 20, device, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cur_len 1\n",
            "word 3 has tensor([ 6.2015, -5.5238, -6.0122,  ..., -0.5067, -1.8321, -6.6582])\n",
            "beam_scores.shape first time torch.Size([4136])\n",
            "self.size 4 flat_beam_scores.shape torch.Size([4136])\n",
            "best_scores tensor([21.5089, 21.0419, 16.5810, 15.8958]) best_scores_id tensor([ 783, 1613, 1234,   22])\n",
            "num_words 4136\n",
            "self.prev_ks [tensor([0, 0, 0, 0])]\n",
            "self.next_ys [tensor([2, 1, 1, 1]), tensor([ 783, 1613, 1234,   22])]\n",
            "cur_len 2\n",
            "word 3 has tensor([ 6.4400, -5.5701, -6.0114,  ...,  0.1376, -1.6764, -6.3570])\n",
            "self.size 4 flat_beam_scores.shape torch.Size([16544])\n",
            "best_scores tensor([40.8862, 40.0506, 37.3048, 37.2654]) best_scores_id tensor([  22, 1360,   13,   10])\n",
            "num_words 4136\n",
            "self.prev_ks [tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0])]\n",
            "self.next_ys [tensor([2, 1, 1, 1]), tensor([ 783, 1613, 1234,   22]), tensor([  22, 1360,   13,   10])]\n",
            "cur_len 3\n",
            "word 3 has tensor([ 6.9119, -5.8007, -6.2600,  ..., -0.1259, -1.6524, -6.1620])\n",
            "self.size 4 flat_beam_scores.shape torch.Size([16544])\n",
            "best_scores tensor([60.0824, 56.0421, 55.7184, 55.4701]) best_scores_id tensor([  13,    0, 1613, 1054])\n",
            "num_words 4136\n",
            "self.prev_ks [tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0])]\n",
            "self.next_ys [tensor([2, 1, 1, 1]), tensor([ 783, 1613, 1234,   22]), tensor([  22, 1360,   13,   10]), tensor([  13,    0, 1613, 1054])]\n",
            "cur_len 4\n",
            "word 3 has tensor([ 7.0723, -5.6396, -6.1200,  ...,  0.3759, -1.7606, -5.9661])\n",
            "self.size 4 flat_beam_scores.shape torch.Size([16544])\n",
            "best_scores tensor([86.7131, 77.9913, 76.0756, 75.8127]) best_scores_id tensor([3442, 4012,  573, 2431])\n",
            "num_words 4136\n",
            "self.prev_ks [tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0])]\n",
            "self.next_ys [tensor([2, 1, 1, 1]), tensor([ 783, 1613, 1234,   22]), tensor([  22, 1360,   13,   10]), tensor([  13,    0, 1613, 1054]), tensor([3442, 4012,  573, 2431])]\n",
            "cur_len 5\n",
            "self.size 4 flat_beam_scores.shape torch.Size([16544])\n",
            "best_scores tensor([104.0042, 101.8406, 101.6148, 100.4620]) best_scores_id tensor([   5,  542, 1757,    0])\n",
            "num_words 4136\n",
            "self.prev_ks [tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0])]\n",
            "self.next_ys [tensor([2, 1, 1, 1]), tensor([ 783, 1613, 1234,   22]), tensor([  22, 1360,   13,   10]), tensor([  13,    0, 1613, 1054]), tensor([3442, 4012,  573, 2431]), tensor([   5,  542, 1757,    0])]\n",
            "cur_len 6\n",
            "self.size 4 flat_beam_scores.shape torch.Size([16544])\n",
            "best_scores tensor([124.7591, 119.1938, 118.7754, 117.2222]) best_scores_id tensor([1281, 3455, 3176,  926])\n",
            "num_words 4136\n",
            "self.prev_ks [tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0])]\n",
            "self.next_ys [tensor([2, 1, 1, 1]), tensor([ 783, 1613, 1234,   22]), tensor([  22, 1360,   13,   10]), tensor([  13,    0, 1613, 1054]), tensor([3442, 4012,  573, 2431]), tensor([   5,  542, 1757,    0]), tensor([1281, 3455, 3176,  926])]\n",
            "cur_len 7\n",
            "self.size 4 flat_beam_scores.shape torch.Size([16544])\n",
            "best_scores tensor([139.3645, 139.1792, 137.4937, 137.1094]) best_scores_id tensor([   3, 1281,  255,    0])\n",
            "num_words 4136\n",
            "self.prev_ks [tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0]), tensor([0, 0, 0, 0])]\n",
            "self.next_ys [tensor([2, 1, 1, 1]), tensor([ 783, 1613, 1234,   22]), tensor([  22, 1360,   13,   10]), tensor([  13,    0, 1613, 1054]), tensor([3442, 4012,  573, 2431]), tensor([   5,  542, 1757,    0]), tensor([1281, 3455, 3176,  926]), tensor([   3, 1281,  255,    0])]\n",
            "[tensor(139.3645)] [(7, 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awVWJOXlPjhx",
        "outputId": "e19550d5-f612-4e7b-fa56-d748fe727b95"
      },
      "source": [
        "# Tram nam trong coi nguoi ta\n",
        "for prediction in beam['predictions'][0]:\n",
        "  print(' '.join(tone_vocab.itos[idx] for idx in prediction[:-1]))\n",
        "  # print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trăm năm trong cõi người ta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myt91oV71L_Y",
        "outputId": "0d225fd2-ddd5-4605-9184-f606c3ae3a37"
      },
      "source": [
        "# encoder attention: (batch_size*num_head x num_steps x num_steps)\n",
        "net.encoder.attention_weights[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 6, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dNhPm2ADpyP"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "-Dhw1afQD7cY",
        "outputId": "e093772a-2183-4b55-ff72-cd89cd984a5c"
      },
      "source": [
        "num_layers = len(net.encoder.attention_weights)\n",
        "num_heads, num_steps, _ = net.encoder.attention_weights[0].shape\n",
        "fig, ax = plt.subplots(2, 4, figsize=(16, 9))\n",
        "for layer in range(num_layers):\n",
        "  for head in range(num_heads):\n",
        "    ax[layer, head] = sns.heatmap(net.encoder.attention_weights[layer][head], \n",
        "                                  ax=ax[layer, head],\n",
        "                                  xticklabels=[w for w in sentence.split()] + [\"<eos>\"],\n",
        "                                  yticklabels=[w for w in sentence.split()] + [\"<eos>\"])\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHfW0Ld0n-iV"
      },
      "source": [
        "# Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPLEFmUSikhw"
      },
      "source": [
        "def inference(sentence):\n",
        "  beam = evaluate(net, sentence, no_tone_vocab, tone_vocab, 20, device, 4)\n",
        "  if len(beam['predictions'][0]) > 0:\n",
        "    return ' '.join(tone_vocab.itos[idx] for idx in beam['predictions'][0][0][:-1])\n",
        "  else:\n",
        "    return ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xMB9ajAgjJ0G",
        "outputId": "73a977da-1ed7-460d-ee51-e40e57d1c439"
      },
      "source": [
        "inference(\"tram nam roi lai ra di\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'trăm năm rồi lại ra đi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0vmaVdVj5eL",
        "outputId": "75ca3dcb-edc2-420e-bac4-f16c0affacea"
      },
      "source": [
        "%%time\n",
        "df_test['predict'] = df_test.text_clean_no_accent.apply(inference)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 37s, sys: 1.03 s, total: 1min 38s\n",
            "Wall time: 49.7 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5C2sz9Ckmji3",
        "outputId": "aa6b9e29-4851-4919-f2c9-e7f3a51b9b00"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_no_accent</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9478271</th>\n",
              "      <td>quan hệ quốc phòng mỹ ấn độ thắt chặt sau thỏa...</td>\n",
              "      <td>quan he quoc phong my an do that chat sau thoa...</td>\n",
              "      <td>quan hệ quốc phòng mỹ ấn độ thắt chặt sau thỏa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478272</th>\n",
              "      <td>xin lãnh đạo nhịn phát biểu khai giảng</td>\n",
              "      <td>xin lanh dao nhin phat bieu khai giang</td>\n",
              "      <td>xin lãnh đạo phật phát biểu khải giang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478273</th>\n",
              "      <td>bđbp tỉnh quảng nam nhận trách nhiệm trong vụ ...</td>\n",
              "      <td>bdbp tinh quang nam nhan trach nhiem trong vu ...</td>\n",
              "      <td>bđbp tỉnh quảng nam nhận trách nhiệm trong vụ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478274</th>\n",
              "      <td>premier league hù dọa châu âu bằng tỷ bảng</td>\n",
              "      <td>premier league hu doa chau au bang ty bang</td>\n",
              "      <td>premier league &lt;unk&gt; đóa châu âu bằng tỷ bằng</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478275</th>\n",
              "      <td>năm thực hiện tái cơ cấu nông nghiệp mờ nhạt b...</td>\n",
              "      <td>nam thuc hien tai co cau nong nghiep mo nhat b...</td>\n",
              "      <td>năm thực hiện tại cơ cấu nông nghiệp mờ nhất b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479266</th>\n",
              "      <td>vợ đòi ly hôn vì chồng bạo hành suốt năm</td>\n",
              "      <td>vo doi ly hon vi chong bao hanh suot nam</td>\n",
              "      <td>vợ đòi ly hôn vì chồng bảo hạnh suốt năm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479267</th>\n",
              "      <td>ppi những e ngại về chất lượng tài sản</td>\n",
              "      <td>ppi nhung e ngai ve chat luong tai san</td>\n",
              "      <td>&lt;unk&gt; những ế &lt;unk&gt; về chất lượng tài sản</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479268</th>\n",
              "      <td>quân đội syria mở rộng vây lấn tấn công trên v...</td>\n",
              "      <td>quan doi syria mo rong vay lan tan cong tren v...</td>\n",
              "      <td>quân đội syria mở rộng vây lần tấn công trên v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479269</th>\n",
              "      <td>cháy siêu thị co opmart tiểu thương hoảng loạn...</td>\n",
              "      <td>chay sieu thi co opmart tieu thuong hoang loan...</td>\n",
              "      <td>cháy siêu thị có &lt;unk&gt; tiểu thương hoảng loạn ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479270</th>\n",
              "      <td>giờ chuyển nhượng cuối cùng tại premier league...</td>\n",
              "      <td>gio chuyen nhuong cuoi cung tai premier league...</td>\n",
              "      <td>giờ chuyển nhượng cuối cùng tại premier league...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text_clean  ...                                            predict\n",
              "9478271  quan hệ quốc phòng mỹ ấn độ thắt chặt sau thỏa...  ...  quan hệ quốc phòng mỹ ấn độ thắt chặt sau thỏa...\n",
              "9478272             xin lãnh đạo nhịn phát biểu khai giảng  ...             xin lãnh đạo phật phát biểu khải giang\n",
              "9478273  bđbp tỉnh quảng nam nhận trách nhiệm trong vụ ...  ...  bđbp tỉnh quảng nam nhận trách nhiệm trong vụ ...\n",
              "9478274         premier league hù dọa châu âu bằng tỷ bảng  ...      premier league <unk> đóa châu âu bằng tỷ bằng\n",
              "9478275  năm thực hiện tái cơ cấu nông nghiệp mờ nhạt b...  ...  năm thực hiện tại cơ cấu nông nghiệp mờ nhất b...\n",
              "...                                                    ...  ...                                                ...\n",
              "9479266           vợ đòi ly hôn vì chồng bạo hành suốt năm  ...           vợ đòi ly hôn vì chồng bảo hạnh suốt năm\n",
              "9479267             ppi những e ngại về chất lượng tài sản  ...          <unk> những ế <unk> về chất lượng tài sản\n",
              "9479268  quân đội syria mở rộng vây lấn tấn công trên v...  ...  quân đội syria mở rộng vây lần tấn công trên v...\n",
              "9479269  cháy siêu thị co opmart tiểu thương hoảng loạn...  ...  cháy siêu thị có <unk> tiểu thương hoảng loạn ...\n",
              "9479270  giờ chuyển nhượng cuối cùng tại premier league...  ...  giờ chuyển nhượng cuối cùng tại premier league...\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyR24KmDkHLU"
      },
      "source": [
        "def sentence_accuracy(row):\n",
        "  src = row.text_clean.split(\" \")\n",
        "  predict = row.predict.split(\" \")\n",
        "  t = 0\n",
        "  for i in range(min(len(src), len(predict))):\n",
        "    if (src[i] == predict[i]):\n",
        "      t += 1\n",
        "  return t/len(src)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6kX41DvnqWV",
        "outputId": "462eadb6-f52b-48d1-c570-32c94afba021"
      },
      "source": [
        "%%time\n",
        "df_test['accuracy'] = df_test.apply(sentence_accuracy, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 29.9 ms, sys: 0 ns, total: 29.9 ms\n",
            "Wall time: 29.8 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "qdUbePz4nY9P",
        "outputId": "7905efeb-2591-4c3f-dc06-94259f641ad5"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_no_accent</th>\n",
              "      <th>predict</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9478271</th>\n",
              "      <td>quan hệ quốc phòng mỹ ấn độ thắt chặt sau thỏa...</td>\n",
              "      <td>quan he quoc phong my an do that chat sau thoa...</td>\n",
              "      <td>quan hệ quốc phòng mỹ ấn độ thắt chặt sau thỏa...</td>\n",
              "      <td>0.928571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478272</th>\n",
              "      <td>xin lãnh đạo nhịn phát biểu khai giảng</td>\n",
              "      <td>xin lanh dao nhin phat bieu khai giang</td>\n",
              "      <td>xin lãnh đạo phật phát biểu khải giang</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478273</th>\n",
              "      <td>bđbp tỉnh quảng nam nhận trách nhiệm trong vụ ...</td>\n",
              "      <td>bdbp tinh quang nam nhan trach nhiem trong vu ...</td>\n",
              "      <td>bđbp tỉnh quảng nam nhận trách nhiệm trong vụ ...</td>\n",
              "      <td>0.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478274</th>\n",
              "      <td>premier league hù dọa châu âu bằng tỷ bảng</td>\n",
              "      <td>premier league hu doa chau au bang ty bang</td>\n",
              "      <td>premier league &lt;unk&gt; đóa châu âu bằng tỷ bằng</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478275</th>\n",
              "      <td>năm thực hiện tái cơ cấu nông nghiệp mờ nhạt b...</td>\n",
              "      <td>nam thuc hien tai co cau nong nghiep mo nhat b...</td>\n",
              "      <td>năm thực hiện tại cơ cấu nông nghiệp mờ nhất b...</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479266</th>\n",
              "      <td>vợ đòi ly hôn vì chồng bạo hành suốt năm</td>\n",
              "      <td>vo doi ly hon vi chong bao hanh suot nam</td>\n",
              "      <td>vợ đòi ly hôn vì chồng bảo hạnh suốt năm</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479267</th>\n",
              "      <td>ppi những e ngại về chất lượng tài sản</td>\n",
              "      <td>ppi nhung e ngai ve chat luong tai san</td>\n",
              "      <td>&lt;unk&gt; những ế &lt;unk&gt; về chất lượng tài sản</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479268</th>\n",
              "      <td>quân đội syria mở rộng vây lấn tấn công trên v...</td>\n",
              "      <td>quan doi syria mo rong vay lan tan cong tren v...</td>\n",
              "      <td>quân đội syria mở rộng vây lần tấn công trên v...</td>\n",
              "      <td>0.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479269</th>\n",
              "      <td>cháy siêu thị co opmart tiểu thương hoảng loạn...</td>\n",
              "      <td>chay sieu thi co opmart tieu thuong hoang loan...</td>\n",
              "      <td>cháy siêu thị có &lt;unk&gt; tiểu thương hoảng loạn ...</td>\n",
              "      <td>0.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479270</th>\n",
              "      <td>giờ chuyển nhượng cuối cùng tại premier league...</td>\n",
              "      <td>gio chuyen nhuong cuoi cung tai premier league...</td>\n",
              "      <td>giờ chuyển nhượng cuối cùng tại premier league...</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text_clean  ...  accuracy\n",
              "9478271  quan hệ quốc phòng mỹ ấn độ thắt chặt sau thỏa...  ...  0.928571\n",
              "9478272             xin lãnh đạo nhịn phát biểu khai giảng  ...  0.625000\n",
              "9478273  bđbp tỉnh quảng nam nhận trách nhiệm trong vụ ...  ...  0.846154\n",
              "9478274         premier league hù dọa châu âu bằng tỷ bảng  ...  0.666667\n",
              "9478275  năm thực hiện tái cơ cấu nông nghiệp mờ nhạt b...  ...  0.714286\n",
              "...                                                    ...  ...       ...\n",
              "9479266           vợ đòi ly hôn vì chồng bạo hành suốt năm  ...  0.800000\n",
              "9479267             ppi những e ngại về chất lượng tài sản  ...  0.666667\n",
              "9479268  quân đội syria mở rộng vây lấn tấn công trên v...  ...  0.846154\n",
              "9479269  cháy siêu thị co opmart tiểu thương hoảng loạn...  ...  0.818182\n",
              "9479270  giờ chuyển nhượng cuối cùng tại premier league...  ...  0.857143\n",
              "\n",
              "[1000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmPUrY72nv8J",
        "outputId": "d352106d-821e-4f45-8b27-0244e235e19b"
      },
      "source": [
        "df_test.accuracy.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.742474838840471"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "uFYxdO4LoENd",
        "outputId": "2459d530-6ca4-46c5-d652-69689bb84cb9"
      },
      "source": [
        "plt.hist(df_test.accuracy, bins=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  7.,   2.,   4.,   2.,   6.,  21.,  10.,  16.,  27.,  20.,  72.,\n",
              "         74.,  49.,  65.,  50.,  86., 134.,  63., 106., 186.]),\n",
              " array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "        0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "fz0xNK1hoJPi",
        "outputId": "69147b10-1b77-4acb-81a5-d8aab0a455a0"
      },
      "source": [
        "df_test[df_test.accuracy < 0.1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_clean_no_accent</th>\n",
              "      <th>predict</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9478409</th>\n",
              "      <td>vào vòng us open venus williams thiết lập kỷ lục</td>\n",
              "      <td>vao vong us open venus williams thiet lap ky luc</td>\n",
              "      <td>&lt;unk&gt; vào hose &lt;unk&gt; &lt;unk&gt; thiết lập kỷ lục me...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478512</th>\n",
              "      <td>nghệ an người dân chưa chịu bàn giao mặt bằng ...</td>\n",
              "      <td>nghe an nguoi dan chua chiu ban giao mat bang ...</td>\n",
              "      <td></td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478664</th>\n",
              "      <td>rosol murray càng đánh càng đuối v us open</td>\n",
              "      <td>rosol murray cang danh cang duoi v us open</td>\n",
              "      <td>&lt;unk&gt; &lt;unk&gt; danh căng cảng dưới căng showbiz &lt;...</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9478777</th>\n",
              "      <td>lấy ý kiến góp ý về dự thảo quy định thực hiện...</td>\n",
              "      <td>lay y kien gop y ve du thao quy dinh thuc hien...</td>\n",
              "      <td></td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479016</th>\n",
              "      <td>xã hồng thái huyện an dương tp hải phòng các c...</td>\n",
              "      <td>xa hong thai huyen an duong tp hai phong cac c...</td>\n",
              "      <td></td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479020</th>\n",
              "      <td>google sẵn sàng ngưng sử dụng thương hiệu điện...</td>\n",
              "      <td>google san sang ngung su dung thuong hieu dien...</td>\n",
              "      <td>google sản &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; hiểu ...</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479084</th>\n",
              "      <td>benzema ráo riết tập luyện chờ ngày tái xuất</td>\n",
              "      <td>benzema rao riet tap luyen cho ngay tai xuat</td>\n",
              "      <td>ráo riết ráo riết tập luyện cho ngày tái xuất</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479089</th>\n",
              "      <td>vụ mùi hôi tấn công người dân khu nam sài gòn ...</td>\n",
              "      <td>vu mui hoi tan cong nguoi dan khu nam sai gon ...</td>\n",
              "      <td></td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9479204</th>\n",
              "      <td>miranda kerr lần đầu nói về ảnh khỏa thân của ...</td>\n",
              "      <td>miranda kerr lan dau noi ve anh khoa than cua ...</td>\n",
              "      <td>ecb lần đầu nỗi đau về anh khoa của chồng cũ c...</td>\n",
              "      <td>0.071429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text_clean  ...  accuracy\n",
              "9478409   vào vòng us open venus williams thiết lập kỷ lục  ...  0.000000\n",
              "9478512  nghệ an người dân chưa chịu bàn giao mặt bằng ...  ...  0.000000\n",
              "9478664         rosol murray càng đánh càng đuối v us open  ...  0.000000\n",
              "9478777  lấy ý kiến góp ý về dự thảo quy định thực hiện...  ...  0.000000\n",
              "9479016  xã hồng thái huyện an dương tp hải phòng các c...  ...  0.000000\n",
              "9479020  google sẵn sàng ngưng sử dụng thương hiệu điện...  ...  0.090909\n",
              "9479084       benzema ráo riết tập luyện chờ ngày tái xuất  ...  0.000000\n",
              "9479089  vụ mùi hôi tấn công người dân khu nam sài gòn ...  ...  0.000000\n",
              "9479204  miranda kerr lần đầu nói về ảnh khỏa thân của ...  ...  0.071429\n",
              "\n",
              "[9 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    }
  ]
}