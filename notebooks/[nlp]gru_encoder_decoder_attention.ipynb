{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuEKX3p4Lj7Z",
    "outputId": "bf6ee0f4-ff1e-4d7f-a35f-450e4374c7cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jnHMAkMA0WmC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from typing import Tuple\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rhZ9e6-I0hz1"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80H2zKgHnHfV"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "X6hhbQXd0ZDo"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/NMT/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "loHhuV2S0aiL"
   },
   "outputs": [],
   "source": [
    "# tokenize by space\n",
    "tokenizer = get_tokenizer(tokenizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "d00ytWbb0bqj"
   },
   "outputs": [],
   "source": [
    "def build_vocab(iter_text_data, tokenizer):\n",
    "    counter = Counter()\n",
    "    for line in iter_text_data:#df.text_clean.to_numpy():\n",
    "        counter.update(tokenizer(line))\n",
    "    return Vocab(counter, min_freq=1000, specials=['<unk>', '<pad>', '<bos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTlPalea0bh4",
    "outputId": "c99e5a18-6a62-4198-c5c5-b20ed03ebe5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 171 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tone_vocab = build_vocab(df.text_clean.to_numpy(), tokenizer)\n",
    "no_tone_vocab = build_vocab(df.text_clean_no_accent.to_numpy(), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6aTKTvbOpyk",
    "outputId": "94653a73-6d82-4b5e-9d3c-78be1c76d19b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4136, 2248)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tone_vocab), len(no_tone_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5IybvC0Q0dVB"
   },
   "outputs": [],
   "source": [
    "def data_process(tone_array, no_tone_array, tone_vocab, no_tone_vocab, tokenizer):\n",
    "    data = []\n",
    "    for (tone_str, no_tone_str) in tqdm(zip(tone_array, no_tone_array)):\n",
    "#         print(tone_str, no_tone_str)\n",
    "#         break\n",
    "        tone_tensor_ = torch.tensor([tone_vocab[token] for token in tokenizer(tone_str)],\n",
    "                                dtype=torch.long)\n",
    "        no_tone_tensor_ = torch.tensor([no_tone_vocab[token] for token in tokenizer(no_tone_str)],\n",
    "                                dtype=torch.long)\n",
    "        data.append((tone_tensor_, no_tone_tensor_))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBJ8nM_t0ebI",
    "outputId": "c8233bad-bd00-4a3d-efff-cc476eefda9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 2), (1000, 2))"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_range = 100000#int(df.shape[0]*1/100)\n",
    "test_range = 1000#int(df.shape[0]*0.5/100)\n",
    "df_train = df.iloc[:train_range, :]\n",
    "df_test = df.iloc[-test_range:, :]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ZCeLte6mr22g",
    "outputId": "e94df975-03b2-4c74-97a0-e5e940b9fb37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_clean_no_accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chây ì nộp phạt nguội</td>\n",
       "      <td>chay i nop phat nguoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cháu đòi tiền cơm dì đòi tiền nhà</td>\n",
       "      <td>chau doi tien com di doi tien nha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>đà nẵng nghiên cứu tiện ích nhắn tin khi vi ph...</td>\n",
       "      <td>da nang nghien cuu tien ich nhan tin khi vi ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>khó xử vụ mẹ tuổi trộm xe hơi của con gái</td>\n",
       "      <td>kho xu vu me tuoi trom xe hoi cua con gai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thay đổi về đăng ký chuyển nhượng xe từ bạn cầ...</td>\n",
       "      <td>thay doi ve dang ky chuyen nhuong xe tu ban ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>những khoảnh khắc thảm họa thiên nhiên đáng sợ...</td>\n",
       "      <td>nhung khoanh khac tham hoa thien nhien dang so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>yemen đơn vị điều tra hình sự bị không kích nh...</td>\n",
       "      <td>yemen don vi dieu tra hinh su bi khong kich nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>nguyên nhân tàu chở khách đâm tàu chở hàng tại mỹ</td>\n",
       "      <td>nguyen nhan tau cho khach dam tau cho hang tai my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>thổ nhĩ kỳ cảnh báo binh sĩ mỹ tại các khu vực...</td>\n",
       "      <td>tho nhi ky canh bao binh si my tai cac khu vuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>tàu hỏa đâm trúng tàu chở hàng ở mỹ khiến hơn ...</td>\n",
       "      <td>tau hoa dam trung tau cho hang o my khien hon ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_clean                               text_clean_no_accent\n",
       "0                                 chây ì nộp phạt nguội                              chay i nop phat nguoi\n",
       "1                     cháu đòi tiền cơm dì đòi tiền nhà                  chau doi tien com di doi tien nha\n",
       "2     đà nẵng nghiên cứu tiện ích nhắn tin khi vi ph...  da nang nghien cuu tien ich nhan tin khi vi ph...\n",
       "3             khó xử vụ mẹ tuổi trộm xe hơi của con gái          kho xu vu me tuoi trom xe hoi cua con gai\n",
       "4     thay đổi về đăng ký chuyển nhượng xe từ bạn cầ...  thay doi ve dang ky chuyen nhuong xe tu ban ca...\n",
       "...                                                 ...                                                ...\n",
       "9995  những khoảnh khắc thảm họa thiên nhiên đáng sợ...  nhung khoanh khac tham hoa thien nhien dang so...\n",
       "9996  yemen đơn vị điều tra hình sự bị không kích nh...  yemen don vi dieu tra hinh su bi khong kich nh...\n",
       "9997  nguyên nhân tàu chở khách đâm tàu chở hàng tại mỹ  nguyen nhan tau cho khach dam tau cho hang tai my\n",
       "9998  thổ nhĩ kỳ cảnh báo binh sĩ mỹ tại các khu vực...  tho nhi ky canh bao binh si my tai cac khu vuc...\n",
       "9999  tàu hỏa đâm trúng tàu chở hàng ở mỹ khiến hơn ...  tau hoa dam trung tau cho hang o my khien hon ...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5W47MSd0fmN",
    "outputId": "165d1f66-dac6-4247-a9a8-d8f981912539"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2732it [00:00, 27312.54it/s]\u001b[A\n",
      "5303it [00:00, 26806.01it/s]\u001b[A\n",
      "8219it [00:00, 27470.25it/s]\u001b[A\n",
      "10035it [00:00, 21966.15it/s]\u001b[A\n",
      "12624it [00:00, 23008.82it/s]\u001b[A\n",
      "14920it [00:00, 22993.51it/s]\u001b[A\n",
      "17010it [00:00, 22322.30it/s]\u001b[A\n",
      "19769it [00:00, 19434.38it/s]\u001b[A\n",
      "22394it [00:01, 21076.05it/s]\u001b[A\n",
      "24514it [00:01, 20931.45it/s]\u001b[A\n",
      "27875it [00:01, 23600.16it/s]\u001b[A\n",
      "30355it [00:01, 23019.62it/s]\u001b[A\n",
      "32953it [00:01, 23832.49it/s]\u001b[A\n",
      "35405it [00:01, 23418.89it/s]\u001b[A\n",
      "38175it [00:01, 24556.70it/s]\u001b[A\n",
      "41163it [00:01, 25942.31it/s]\u001b[A\n",
      "43813it [00:01, 25011.45it/s]\u001b[A\n",
      "46507it [00:01, 25557.72it/s]\u001b[A\n",
      "49098it [00:02, 22595.86it/s]\u001b[A\n",
      "51446it [00:02, 17464.18it/s]\u001b[A\n",
      "54520it [00:02, 20062.88it/s]\u001b[A\n",
      "57220it [00:02, 21738.01it/s]\u001b[A\n",
      "59649it [00:02, 22407.25it/s]\u001b[A\n",
      "62520it [00:02, 23987.02it/s]\u001b[A\n",
      "65079it [00:02, 19504.12it/s]\u001b[A\n",
      "67686it [00:03, 21095.49it/s]\u001b[A\n",
      "70028it [00:03, 21742.68it/s]\u001b[A\n",
      "72434it [00:03, 22389.59it/s]\u001b[A\n",
      "74785it [00:03, 20842.67it/s]\u001b[A\n",
      "77694it [00:03, 22778.35it/s]\u001b[A\n",
      "80096it [00:03, 18928.51it/s]\u001b[A\n",
      "82185it [00:03, 13582.06it/s]\u001b[A\n",
      "83893it [00:03, 13868.32it/s]\u001b[A\n",
      "86144it [00:04, 15671.19it/s]\u001b[A\n",
      "89010it [00:04, 18136.35it/s]\u001b[A\n",
      "91142it [00:04, 17076.70it/s]\u001b[A\n",
      "93402it [00:04, 18427.09it/s]\u001b[A\n",
      "95441it [00:04, 18443.80it/s]\u001b[A\n",
      "100000it [00:04, 21113.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "train_data = data_process(df_train.text_clean.to_numpy(), \n",
    "                          df_train.text_clean_no_accent.to_numpy(), \n",
    "                          tone_vocab, no_tone_vocab, tokenizer)\n",
    "# val_data = data_process(df_test.text_clean.to_numpy(), \n",
    "#                           df_test.text_clean_no_accent.to_numpy(), \n",
    "#                           tone_vocab, no_tone_vocab, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40YEENGb0gvH",
    "outputId": "cc2d20f1-fd16-4274-c995-981def87bf42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1000it [00:00, 28774.82it/s]\n"
     ]
    }
   ],
   "source": [
    "val_data = data_process(df_test.text_clean.to_numpy(), \n",
    "                          df_test.text_clean_no_accent.to_numpy(), \n",
    "                          tone_vocab, no_tone_vocab, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "LtRWyDdA0itJ"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "PAD_IDX = tone_vocab['<pad>']\n",
    "BOS_IDX = tone_vocab['<bos>']\n",
    "EOS_IDX = tone_vocab['<eos>']\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    tone_batch, no_tone_batch = [], []\n",
    "    for (tone_item, no_tone_item) in data_batch:\n",
    "        tone_batch.append(torch.cat([tone_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        no_tone_batch.append(torch.cat([no_tone_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        \n",
    "    tone_batch = pad_sequence(tone_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    no_tone_batch = pad_sequence(no_tone_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    return no_tone_batch, tone_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zU4TcfdhYtrO",
    "outputId": "5294702f-416a-419e-a880-ac13f1f4cd2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_IDX, BOS_IDX, EOS_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtMSDuN10j6n",
    "outputId": "fa4a5e5f-4a5e-4baa-8fb4-4370b9dea438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 ms, sys: 6 µs, total: 1.25 ms\n",
      "Wall time: 1.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0Nq5Uie0lGA",
    "outputId": "b486b41a-deb1-4b96-ce44-03c3b69bd6a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 28]) torch.Size([64, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for X, y in train_iter:\n",
    "    # max_len = max(max_len, X.shape[1])\n",
    "    print(X.shape, y.shape)\n",
    "    break\n",
    "    # break\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYRBtGxgnK5U"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jgJgSfgn0mHq"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 embed_size: int,\n",
    "                 num_hiddens: int,\n",
    "                 num_layers: int,\n",
    "                 dropout: float):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # X: (batch_size x num_steps)\n",
    "\n",
    "    def forward(self,\n",
    "                X: Tensor) -> Tuple[Tensor]:\n",
    "        X = self.dropout(self.embedding(X))\n",
    "        # X: (batch_size, num_steps, embed_size)\n",
    "\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # X: (num_steps, batch_size, embed_size)\n",
    "        \n",
    "        output, state = self.rnn(X)\n",
    "        # output: (num_steps, batch_size, num_hiddens)\n",
    "        # state : (num_layers, batch_size, num_hiddens)\n",
    "        \n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "n3VikDsTABit"
   },
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "  def __init__(self, key_size, query_size, num_hiddens, dropout):\n",
    "    super().__init__()\n",
    "    self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "    self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "    self.W_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  # query:  (batch_size x 1 x num_hiddens)\n",
    "  # keys:   (batch_size, num_steps, num_hiddens)\n",
    "  # values: (batch_size, num_steps, num_hiddens)\n",
    "  # mask:   (batch_size x 1 x num_steps)\n",
    "  def forward(self, queries, keys, values, mask):\n",
    "    queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "    # query:  (batch_size x 1 x num_hiddens)\n",
    "    # keys:   (batch_size, num_steps, num_hiddens)\n",
    "    # i choosed key_size = num_hiddens\n",
    "\n",
    "    # queries: (batch_size x 1 x 1 x num_hiddens) `1 query`\n",
    "    # keys:    (batch_size x 1 x num_steps x num_hiddens)\n",
    "    # broadcast sum\n",
    "    features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "    # features: (batch_size x 1 x num_steps x num_hiddens)\n",
    "\n",
    "    features = torch.tanh(features)\n",
    "\n",
    "    scores = self.W_v(features).squeeze(-1)\n",
    "    # scores: (batch_size x 1 x num_steps x 1).squeeze(-1): (batch_size x 1 x num_steps)\n",
    "\n",
    "    self._attention_weights = F.softmax(scores.masked_fill(mask=mask, value=-np.inf), dim=-1)\n",
    "    \n",
    "    # return shape: (batch_size, 1, num_hiddens) `1 query`\n",
    "    return torch.bmm(self._attention_weights, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osvOvjMQL40_",
    "outputId": "3758eb54-a7e7-42e5-ebfc-6b9461f10ed0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 4]), torch.Size([2, 10, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones(2, 10, 2)\n",
    "values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)\n",
    "\n",
    "attention = AdditiveAttention(2, 20, 8, 0.1)\n",
    "attention.eval()\n",
    "mask = torch.stack([torch.cat((torch.zeros(2), torch.ones(8))),\n",
    "                    torch.cat((torch.zeros(6), torch.ones(4)))]).unsqueeze(1).type(torch.bool)\n",
    "attention(queries, keys, values, mask).shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jyHvafd-0nGH"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 embed_size: int,\n",
    "                 num_hiddens: int,\n",
    "                 num_layers: int,\n",
    "                 dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.attention = AdditiveAttention(num_hiddens, num_hiddens, num_hiddens, dropout)\n",
    "        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self._attention_weights = []\n",
    "    \n",
    "    def init_state(self, enc_outputs):\n",
    "      # outputs (num_steps x batch_size x num_hidden)\n",
    "      outputs, hidden_states = enc_outputs\n",
    "      return (outputs.permute(1, 0, 2), hidden_states)\n",
    "    \n",
    "    # X:     (batch_size x num_steps)\n",
    "    # state: ((batch_size, num_steps, num_hiddens), (num_layers, batch_size, num_hiddens))\n",
    "    # mask:  (batch_size x 1 x num_steps)\n",
    "    def forward(self,\n",
    "                X: Tensor,\n",
    "                state: Tensor,\n",
    "                mask: Tensor) -> Tuple[Tensor]:\n",
    "        X = self.dropout(self.embedding(X))\n",
    "        # X: (batch_size x num_steps x embed_size)\n",
    "\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # X: (num_steps x batch_size x embed_size)\n",
    "\n",
    "        enc_outputs, hidden_state = state\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        # for every steps\n",
    "        for x in X:\n",
    "          query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
    "          # query: (batch_size x 1 x num_hiddens)\n",
    "          context = self.attention(query, enc_outputs, enc_outputs, mask)\n",
    "          # context: (batch_size, 1, num_hiddens)\n",
    "          x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
    "          # x = (batch_size, 1, num_hiddens) cat with (batch_size x 1 x embed_size)\n",
    "          # x: (batch_size, 1, num_hiddens + embed_size)\n",
    "          output, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
    "          # output      : (1, batch_size, num_hiddens + embed_size)\n",
    "          # hidden_state: (num_layers, batch_size, num_hiddens)\n",
    "\n",
    "          outputs.append(output)\n",
    "          self._attention_weights.append(self.attention._attention_weights)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "        outputs = self.log_softmax(outputs)\n",
    "\n",
    "        # return shape: (batch_size, num_steps, vocab_size), [(batch_size, num_steps, num_hiddens), (num_layers, batch_size, num_hiddens)]\n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3Pkf84fe0oeR"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder: nn.Module,\n",
    "                 decoder: nn.Module,\n",
    "                 pad_idx: int,\n",
    "                 device: torch.device,):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "        self.device = device\n",
    "    def create_mask(self, src):\n",
    "      return (src == self.pad_idx).unsqueeze(1)\n",
    "    \n",
    "    # enc_x: (batch_size x num_steps)\n",
    "    # dec_X: (batch_size x num_steps)\n",
    "    def forward(self,\n",
    "                enc_X: Tensor,\n",
    "                dec_X: Tensor) -> Tensor:\n",
    "        mask = self.create_mask(enc_X)\n",
    "        # mask: (batch_size x 1 x num_steps)\n",
    "\n",
    "        enc_outputs = self.encoder(enc_X)\n",
    "        # enc_outputs\n",
    "        # output: (num_steps, batch_size, num_hiddens)\n",
    "        # state : (num_layers, batch_size, num_hiddens)\n",
    "\n",
    "        dec_state = self.decoder.init_state(enc_outputs)\n",
    "        # dec_state: ((batch_size, num_steps, num_hiddens), (num_layers, batch_size, num_hiddens))\n",
    "\n",
    "        return self.decoder(dec_X, dec_state, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9lWZ6xBneVd"
   },
   "source": [
    "# Train & evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_0NQ7jOm0pgT"
   },
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, no_tone_vocab, device):\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    PAD_IDX = tone_vocab.stoi['<pad>']\n",
    "    loss = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "    net.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in tqdm(data_iter, position=0, leave=True):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            X, Y = [x.to(device) for x in batch]\n",
    "            # X: (batch_size x num_steps)\n",
    "            # Y: (batch_size x num_steps)\n",
    "\n",
    "            bos = torch.tensor([tone_vocab.stoi['<bos>']]*Y.shape[0], device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1) # teacher forcing\n",
    "\n",
    "            # dec_input: (batch_size x num_steps)\n",
    "\n",
    "            Y_hat, _ = net(X, dec_input)\n",
    "            # Y_hat: (batch_size, num_steps, vocab_size)\n",
    "            # _: [(batch_size, num_steps, num_hiddens), (num_layers, batch_size, num_hiddens)]\n",
    "\n",
    "            l = loss(Y_hat.permute(0, 2, 1), Y)#nn.functional.one_hot(Y, len(no_tone_vocab)).squeeze())\n",
    "            \n",
    "            l.backward()\n",
    "            \n",
    "            # clip gradient\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            epoch_loss += l.item()\n",
    "        if ((epoch + 1) % 1 == 0):\n",
    "            print(f'Epoch {epoch}, Loss {epoch_loss/len(data_iter):.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "QHQjcmYQ5so2"
   },
   "outputs": [],
   "source": [
    "def evaluate(net, sentence, no_tone_vocab, tone_vocab, max_length, device, beam_size):\n",
    "  net.eval()\n",
    "\n",
    "  src_tokens = [no_tone_vocab.stoi[word] for word in sentence.lower().split(\" \")] + [no_tone_vocab.stoi['<eos>']]\n",
    "\n",
    "  # unsqueeze add batch dim\n",
    "  enc_X = torch.unsqueeze(\n",
    "      torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0\n",
    "  )\n",
    "  mask = (enc_X == no_tone_vocab.stoi['<pad>']).unsqueeze(1)\n",
    "\n",
    "  #TODO: add attention to beam\n",
    "  net.decoder._attention_weights = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    enc_outputs = net.encoder(enc_X)\n",
    "    # enc_outputs\n",
    "    # output: (num_steps, batch_size, num_hiddens)\n",
    "    # state : (num_layers, batch_size, num_hiddens)\n",
    "  \n",
    "  outputs, dec_state = net.decoder.init_state(enc_outputs)\n",
    "  # outputs:   (batch_size, num_steps, num_hiddens)\n",
    "  # dec_state: (num_layers, batch_size, num_hiddens)\n",
    "  \n",
    "  outputs = outputs.repeat((beam_size, 1, 1))\n",
    "  dec_state = dec_state.repeat((1, beam_size, 1))\n",
    "\n",
    "\n",
    "  beam = [Beam(beam_size, 1, 2, 3, GNMTGlobalScorer(), 5) for _ in range(1)]\n",
    "  \n",
    "\n",
    "  for i in range(max_length):\n",
    "    if all((b.done() for b in beam)):\n",
    "      break\n",
    "    with torch.no_grad():\n",
    "      dec_X = torch.stack([b.get_current_state() for b in beam]).t().contiguous().view(1, -1).t().to(device)\n",
    "      Y, (outputs, dec_state) = net.decoder(dec_X, (outputs, dec_state), mask)\n",
    "      # Y:        (batch_size, num_steps, vocab_size)\n",
    "      # outputs:  (batch_size, num_steps, num_hiddens)\n",
    "      # dec_state:(num_layers, batch_size, num_hiddens)\n",
    "\n",
    "      select_indices_array = []\n",
    "      for j, b in enumerate(beam):\n",
    "        b.advance(Y[:, j])\n",
    "        select_indices_array.append(b.get_current_origin() * 1 + j)\n",
    "      \n",
    "      select_indices = torch.cat(select_indices_array) \\\n",
    "                      .view(1, beam_size) \\\n",
    "                      .transpose(0, 1) \\\n",
    "                      .contiguous() \\\n",
    "                      .view(-1).type(torch.int32).to(device)\n",
    "      \n",
    "      dec_state = dec_state.index_select(1, select_indices)\n",
    "  ret = _from_beam(beam)\n",
    "  return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8H6Mpzu6ni6E"
   },
   "source": [
    "# Train in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RwzNj9s0qnD",
    "outputId": "bdc8af21-089e-48bf-b086-9f3e7b50861c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(2248, 128)\n",
       "    (rnn): GRU(128, 128)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(4136, 128)\n",
       "    (attention): AdditiveAttention(\n",
       "      (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
       "      (W_v): Linear(in_features=128, out_features=1, bias=False)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (rnn): GRU(256, 128)\n",
       "    (dense): Linear(in_features=128, out_features=4136, bias=True)\n",
       "    (log_softmax): LogSoftmax(dim=2)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tone_vocab_size = len(tone_vocab)\n",
    "no_tone_vocab_size = len(no_tone_vocab)\n",
    "\n",
    "embed_size = 128\n",
    "num_hiddens = 128\n",
    "num_layers = 1\n",
    "dropout = 0.0\n",
    "\n",
    "lr = 0.008\n",
    "num_epochs = 20\n",
    "\n",
    "enc = Encoder(no_tone_vocab_size, embed_size, num_hiddens, num_layers, dropout)\n",
    "\n",
    "dec = Decoder(tone_vocab_size, embed_size, num_hiddens, num_layers, dropout)\n",
    "\n",
    "net = Seq2Seq(enc, dec, tone_vocab.stoi['<pad>'], device).to(device)\n",
    "\n",
    "net.load_state_dict(torch.load(\"/content/drive/MyDrive/Colab Notebooks/gru_encoder_decoder_attention_weights_correct.pth\", map_location=torch.device('cpu')))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNsBsIpc0r-y",
    "outputId": "03370eaa-099d-4f14-a20e-536681b23fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,630,888 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(net):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_oH-aOn0tLc",
    "outputId": "b83e9545-b07a-4c81-c802-b05e61e528a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:13<00:00, 11.70it/s]\n",
      "  0%|          | 2/1563 [00:00<02:21, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 2.8661183019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:10<00:00, 11.94it/s]\n",
      "  0%|          | 2/1563 [00:00<02:11, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1.2553576452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:12<00:00, 11.80it/s]\n",
      "  0%|          | 1/1563 [00:00<02:52,  9.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 1.1172081811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:10<00:00, 11.94it/s]\n",
      "  0%|          | 2/1563 [00:00<01:57, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 0.8600581089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:10<00:00, 11.99it/s]\n",
      "  0%|          | 2/1563 [00:00<02:14, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.6470306327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:13<00:00, 11.71it/s]\n",
      "  0%|          | 2/1563 [00:00<02:11, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 0.5648341948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:14<00:00, 11.66it/s]\n",
      "  0%|          | 2/1563 [00:00<02:19, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 0.5243893058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:10<00:00, 11.96it/s]\n",
      "  0%|          | 2/1563 [00:00<02:07, 12.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.5347159102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:05<00:00, 12.49it/s]\n",
      "  0%|          | 2/1563 [00:00<01:53, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.5094209996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:06<00:00, 12.33it/s]\n",
      "  0%|          | 2/1563 [00:00<02:06, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.5179095048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:08<00:00, 12.15it/s]\n",
      "  0%|          | 2/1563 [00:00<02:16, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.4970319890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:06<00:00, 12.39it/s]\n",
      "  0%|          | 2/1563 [00:00<02:03, 12.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss 0.4964913048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:06<00:00, 12.40it/s]\n",
      "  0%|          | 2/1563 [00:00<01:58, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss 0.4955945895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:07<00:00, 12.29it/s]\n",
      "  0%|          | 2/1563 [00:00<01:53, 13.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss 0.4899392009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:08<00:00, 12.19it/s]\n",
      "  0%|          | 2/1563 [00:00<02:07, 12.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss 0.4800641102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:05<00:00, 12.45it/s]\n",
      "  0%|          | 2/1563 [00:00<02:14, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss 0.4868701970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:06<00:00, 12.32it/s]\n",
      "  0%|          | 2/1563 [00:00<02:11, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss 0.5113624723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:07<00:00, 12.25it/s]\n",
      "  0%|          | 2/1563 [00:00<02:06, 12.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss 0.4964607733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:09<00:00, 12.10it/s]\n",
      "  0%|          | 2/1563 [00:00<02:09, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss 0.5131721485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:09<00:00, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss 0.5142165320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_seq2seq(net, train_iter, lr, num_epochs, no_tone_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "Q1YNckuXtw0O"
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'gru_encoder_decoder_attention_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LckEXlUnYKs"
   },
   "source": [
    "# Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1ItIvkj3ARfO"
   },
   "outputs": [],
   "source": [
    "class GNMTGlobalScorer(object):\n",
    "    \"\"\"\n",
    "    NMT re-ranking score from\n",
    "    \"Google's Neural Machine Translation System\" :cite:`wu2016google`\n",
    "    Args:\n",
    "       alpha (float): length parameter\n",
    "       beta (float):  coverage parameter\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "    def score(self, beam, logprobs):\n",
    "        # \"\"\"\n",
    "        # Rescores a prediction based on penalty functions\n",
    "        # \"\"\"\n",
    "        # normalized_probs = self.length_penalty(beam,\n",
    "        #                                        logprobs,\n",
    "        #                                        self.alpha)\n",
    "        # if not beam.stepwise_penalty:\n",
    "        #     penalty = self.cov_penalty(beam,\n",
    "        #                                beam.global_state[\"coverage\"],\n",
    "        #                                self.beta)\n",
    "        #     normalized_probs -= penalty\n",
    "\n",
    "        return logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5XgD5iauWros"
   },
   "outputs": [],
   "source": [
    "class Beam(object):\n",
    "  def __init__(self, size, pad, bos, eos, global_scorer, min_length):\n",
    "    super().__init__()\n",
    "    self.prev_ks = []\n",
    "    self.scores = torch.FloatTensor(size).zero_()\n",
    "    self.all_scores = []\n",
    "\n",
    "    self.min_length = min_length\n",
    "\n",
    "    self.next_ys = [torch.LongTensor(size)\n",
    "                        .fill_(pad)]\n",
    "    self.next_ys[0][0] = bos\n",
    "\n",
    "    self.finished = []\n",
    "\n",
    "    self.global_scorer = global_scorer\n",
    "\n",
    "    self._eos = eos\n",
    "    self.eos_top = False\n",
    "\n",
    "    self.size = size\n",
    "\n",
    "  def get_current_state(self):\n",
    "    \"Get the outputs for the current timestep.\"\n",
    "    return self.next_ys[-1]\n",
    "\n",
    "  def get_current_origin(self):\n",
    "    \"Get the backpointers for the current timestep.\"\n",
    "    return self.prev_ks[-1]\n",
    "  def done(self):\n",
    "    return self.eos_top\n",
    "  def sort_finished(self, minimum=None):\n",
    "    if minimum is not None:\n",
    "        i = 0\n",
    "        # Add from beam until we have minimum outputs.\n",
    "        while len(self.finished) < minimum:\n",
    "            global_scores = self.global_scorer.score(self, self.scores)\n",
    "            s = global_scores[i]\n",
    "            self.finished.append((s, len(self.next_ys) - 1, i))\n",
    "            i += 1\n",
    "\n",
    "    self.finished.sort(key=lambda a: -a[0])\n",
    "    scores = [sc for sc, _, _ in self.finished]\n",
    "    ks = [(t, k) for _, t, k in self.finished]\n",
    "    return scores, ks\n",
    "\n",
    "  def get_hyp(self, timestep, k):\n",
    "      \"\"\"\n",
    "      Walk back to construct the full hypothesis.\n",
    "      \"\"\"\n",
    "      hyp = []\n",
    "      for j in range(len(self.prev_ks[:timestep]) - 1, -1, -1):\n",
    "          hyp.append(self.next_ys[j + 1][k])\n",
    "          k = self.prev_ks[j][k]\n",
    "      return hyp[::-1]\n",
    "  def advance(self, word_probs):\n",
    "    word_probs = word_probs.unsqueeze(0)\n",
    "    # print(\"word_probs\", word_probs.shape)\n",
    "    num_words = word_probs.size(2)\n",
    "    \n",
    "    # dont let this shit end\n",
    "    cur_len = len(self.next_ys)\n",
    "    # print(\"cur_len\", cur_len)\n",
    "    if cur_len < self.min_length:\n",
    "        for k in range(len(word_probs)):\n",
    "            word_probs[0][k][self._eos] = -1e20\n",
    "            # print(\"word\", self._eos, \"has\", word_probs[k][self._eos])\n",
    "\n",
    "    if len(self.prev_ks) > 0:\n",
    "      beam_scores = word_probs + self.scores.unsqueeze(1).expand_as(word_probs).to(device)\n",
    "      # print(\"beam_scores.shape\", beam_scores.shape, \"word_probs\", word_probs.shape, \"self.scores.unsqueeze(1).expand_as(word_probs)\", self.scores.unsqueeze(1).expand_as(word_probs).shape)\n",
    "      beam_scores = beam_scores.squeeze(0)\n",
    "      # print(\"beam_scores\", beam_scores)\n",
    "      for i in range(self.next_ys[-1].size(0)):\n",
    "        if self.next_ys[-1][i] == self._eos:\n",
    "          # print(\"sentence\", i, 'is ended')\n",
    "          beam_scores[i] = -1e20\n",
    "    else:\n",
    "      beam_scores = word_probs[0][0]\n",
    "      # print(\"beam_scores.shape first time\", beam_scores.shape)\n",
    "\n",
    "    \n",
    "    flat_beam_scores = beam_scores.view(-1)\n",
    "    # print(\"self.size\", self.size, \"flat_beam_scores.shape\", flat_beam_scores.shape)\n",
    "    \n",
    "    best_scores, best_scores_id = flat_beam_scores.topk(self.size, 0,\n",
    "        True, True)\n",
    "    \n",
    "    self.all_scores.append(self.scores)\n",
    "    self.scores = best_scores\n",
    "    # print(\"best_scores\", best_scores, \"best_scores_id\", best_scores_id)\n",
    "    \n",
    "    # print(\"flat_beam_scores\", flat_beam_scores, \"best_scores\", best_scores, \"best_scores_id\", best_scores_id)\n",
    "    # print(\"num_words\", num_words)\n",
    "    prev_k = torch.floor(best_scores_id / num_words).long()\n",
    "    # print(\"prev_k\", prev_k)\n",
    "    self.prev_ks.append(prev_k)\n",
    "    self.next_ys.append((best_scores_id - prev_k * num_words))\n",
    "    # print(\"self.prev_ks\", self.prev_ks)\n",
    "    # print(\"self.next_ys\", self.next_ys)\n",
    "    for i in range(self.next_ys[-1].size(0)):\n",
    "      if self.next_ys[-1][i] == self._eos:\n",
    "        # print(\"self.scores\", self.scores)\n",
    "        global_scores = self.global_scorer.score(self, self.scores)\n",
    "        s = global_scores[i]\n",
    "        self.finished.append((s, len(self.next_ys) - 1, i))\n",
    "\n",
    "    if self.next_ys[-1][0] == self._eos:\n",
    "      self.all_scores.append(self.scores)\n",
    "      self.eos_top = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08mNF2QhZtXj"
   },
   "outputs": [],
   "source": [
    "# a = torch.rand(1, 4136)\n",
    "# b = torch.ones(4, 1)\n",
    "# b.expand_as()\n",
    "# torch.FloatTensor(4).zero_().unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9nbJUZ9KVJ7d"
   },
   "outputs": [],
   "source": [
    "def _from_beam(beam):\n",
    "    ret = {\"predictions\": [],\n",
    "            \"scores\": [],\n",
    "            \"attention\": []}\n",
    "    for b in beam:\n",
    "        # n_best = self.n_best\n",
    "        scores, ks = b.sort_finished(minimum=None)\n",
    "        # print(scores, ks)\n",
    "        hyps, attn = [], []\n",
    "        for i, (times, k) in enumerate(ks):#[:n_best]):\n",
    "            # hyp, att = b.get_hyp(times, k)\n",
    "            hyp = b.get_hyp(times, k)\n",
    "            hyps.append(hyp)\n",
    "            # attn.append(att)\n",
    "        ret[\"predictions\"].append(hyps)\n",
    "        ret[\"scores\"].append(scores)\n",
    "        # ret[\"attention\"].append(attn)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ekw6sJ2EJSVT"
   },
   "outputs": [],
   "source": [
    "sentence = \"tram nam trong coi nguoi ta\"\n",
    "beam = evaluate(net, sentence, no_tone_vocab, tone_vocab, 20, device, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awVWJOXlPjhx",
    "outputId": "d081b9f2-ddad-4a16-8c69-150b58d94e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trạm năm trong cõi người ta\n",
      "trạm năm trong còi người ta\n",
      "trăm năm coi cõi người ta\n",
      "trạm nằm còi còi người ta\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i, prediction in enumerate(beam['predictions'][0]):\n",
    "  predictions.append(' '.join(tone_vocab.itos[idx] for idx in prediction[:-1]))\n",
    "  print(predictions[i])\n",
    "  # print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "yNdPKjVKoKuL"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "pk1joJInkkIm",
    "outputId": "070aa7c7-c0f5-4332-c549-c3768a733430"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_steps = len(net.decoder._attention_weights)\n",
    "batch_size = net.decoder._attention_weights[0].shape[0]\n",
    "heatmap_matrix = torch.cat([steps for steps in net.decoder._attention_weights], dim=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, batch_size, figsize=(16, 4))\n",
    "for batch in range(batch_size):\n",
    "  ax[batch] = sns.heatmap(heatmap_matrix[i], \n",
    "                              ax=ax[batch],\n",
    "                              xticklabels=[w for w in sentence.split()] + [\"<eos>\"],\n",
    "                              yticklabels=[w for w in predictions[batch].split()] + [\"<eos>\"])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzrFEf_dCNey",
    "outputId": "7b968431-ee1f-4c19-9ed2-5135df27f533"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention': [],\n",
       " 'predictions': [[[tensor(279), tensor(3)], [tensor(235), tensor(3)]]],\n",
       " 'scores': [[tensor(-3.4922), tensor(-4.8874)]]}"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMeEsrZItsow"
   },
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "c7WZvCgEtsQE"
   },
   "outputs": [],
   "source": [
    "def inference(sentence):\n",
    "  beam = evaluate(net, sentence, no_tone_vocab, tone_vocab, 20, device, 4)\n",
    "  if len(beam['predictions'][0]) > 0:\n",
    "    return ' '.join(tone_vocab.itos[idx] for idx in beam['predictions'][0][0][:-1])\n",
    "  else:\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "FnM2I-ZYt4_q",
    "outputId": "fb5d3694-2104-4f7a-c267-5b5baba8d025"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'trạm năm rồi lại ra đi'"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(\"tram nam roi lai ra di\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnN6Iur2t6EB",
    "outputId": "1886c53b-b083-4bc1-a4f8-3c389614674a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 s, sys: 9.69 s, total: 49.7 s\n",
      "Wall time: 24.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test['predict'] = df_test.text_clean_no_accent.apply(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "-wdCpBXwuAzZ"
   },
   "outputs": [],
   "source": [
    "def sentence_accuracy(row):\n",
    "  src = row.text_clean.split(\" \")\n",
    "  predict = row.predict.split(\" \")\n",
    "  t = 0\n",
    "  for i in range(min(len(src), len(predict))):\n",
    "    if (src[i] == predict[i]):\n",
    "      t += 1\n",
    "  return t/len(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UufB6RH3uB4C",
    "outputId": "9a789827-b21a-45e3-b263-f049e7e29f82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.5 ms, sys: 0 ns, total: 24.5 ms\n",
      "Wall time: 24.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test['accuracy'] = df_test.apply(sentence_accuracy, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrQn5ulguDFh",
    "outputId": "c5c50ed2-fe52-4b93-b2ed-4570ae2acfa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.712119025788827"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "NMXK32kduEY-",
    "outputId": "2aefc1c5-8c6e-42c2-fef3-6d4b37c976e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 19.,   0.,   7.,   8.,  10.,  20.,  15.,  14.,  23.,  16.,  62.,\n",
       "         64.,  61.,  91.,  72., 101., 134.,  58., 117., 108.]),\n",
       " array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
       "        0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_test.accuracy, bins=20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "[nlp]gru_encoder_decoder_attention",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
